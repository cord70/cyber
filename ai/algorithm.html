<!DOCTYPE html>
<html lang="ru">
 <head>
  <title> Алгоритм самообучения (поиск выгодного поведения) </title>
  <meta content="Одновременное исполнение ранее не синхронных процессов обеспечивает прохождение этим алгоритмом теста на осознавание себя." name="description">
  <meta content="автоматический, адаптация, ассоциативный, восприятие, инстинкт, информация, повтор, повторение, понимание, программирование, рецептор, робот, самоорганизация, стимул, условный, " name="keywords">
  <meta content="Евгений Корниенко" name="author">
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1" name="viewport">
  <link href="https://cord70.github.io/cyber/ai/algorithm.html" rel="canonical">
  <link href="https://cord70.github.io/cyber/favicon.svg" rel="icon" sizes="any" type="image/svg+xml">
  <link href="../images/main.css" rel="stylesheet">
  <script defer="" src="navAI.js"> </script>
  <script defer="" src="../images/ansimeta.js"> </script>
 </head>
 <body>

  <header>
  </header>

  <main>
   <p class="headquote">
    Одновременное исполнение процессов, сохранённых
            в памяти в разное время, обеспечивает прохождение алгоритмом
    <a href="../mind/consciousness.html#selfawaretest">
     теста на
                осознавание себя. </a> </p>

   <h2> Алгоритм самообучения </h2>

   <p> <b> <a title="автор">
      Евгений Корниенко </a> </b> </p>

   <blockquote>
    <p> Доказательством понимания природы и главных принципов работы
                сознания могло бы служить возникновение сознания у специально
                созданного искусственного существа. </p>
   </blockquote>

   <h3> Требуется построить ощущающую машину </h3>

   <p> Мы считаем себя обладающими сознанием, например, потому, что
            мы способны контролировать и обдумывать свои действия. Более простая
            форма сознания заключается в способности осознавать, то есть ощущать
            свои действия и их последствия. Ещё более простой формой сознания
            является способность хотя бы осознавать свои ощущения, что мы
            коротко обозначаем словом "ощущать". </p>

   <p> Поэтому доказательством понимания основ сознания было бы построение
            ощущающей машины. Эту машину можно будет назвать сознательным
            существом, если она будет осознавать не только ощущения, но и
            свои действия, и, тем более, если она сможет обдумывать и планировать
            свои действия. </p>

   <p> Ощущение - это простейшая форма сознания. По мере накопления
            опыта ощущения детализируются, формируются навыки поведения, развивается
            осознание взаимосвязи ощущений и действий. </p>

   <p> Явными признаками сознания являются интеллектуальные способности,
            в частности, творчество и способность к обучению. Связь обучения
            с ощущением прослеживается в
    <a href="../mind/consciousness.html#test">
     <i> тесте на самообучение </i> </a>
    . Из способности к самообучению следует наличие внутреннего
            стремления к определённому состоянию - самоощущению. </p>

   <p> Желаемое внутреннее состояние можно считать заданной от природы
    <i> безусловной потребностью </i> . Технически, можно ввести целевую
            функцию W, пропорциональную
    <i> потребности </i> и зависящую только
            от состояния S сенсоров машины. Минимальное значение этой функции
            соответствует минимальной потребности. Удовлетворение потребности,
            то есть минимум целевой функции W может быть достигнут в результате
    <i> полезного </i> или
    <i> выгодного </i> поведения . </p>

   <p> Если поведение не задано программными и конструктивными средствами,
            и вместе с тем у существа есть встроенные средства запоминания
            выгодного поведения, то происходит самообучение - случайное обнаружение
            и постепенная деталировка выгодного поведения. В процессе самообучения
            у существа развиваются ощущения качеств внешнего мира, зависящих
            от поведения и влияющих на общее состояние этого существа. Ощущение
            &ndash; это субъективное
    <i> измерение </i> своего состояния, необходимое
            при поиске желательного состояния. Существо ориентируется на свои
            ощущения, когда нужно выбрать то или другое поведение. Наблюдаемая
            извне рационализация поведения субъективно состоит в улучшении
            самоощущения, а объективно &ndash; в уменьшении (удовлетворении) потребности. </p>

   <p> Творчество и самообучение - это способности к самостоятельному
            поиску
    <i> полезного поведения </i> , приводящего к удовлетворению
            врождённых, безусловных потребностей. </p>

   <p> Обучение (с учителем) &ndash; это создание специальных условий,
            при которых самообучение приводит к выработке поведения,
    <i> полезного </i> не только ученику, но и учителю. </p>

   <p> Самообучение ещё называется способностью к
    <i> универсальному </i> научению, которое состоит в том, что целевая функция W убывает
            при произвольно заданном (например, случайном) начальном поведении
            и при любых законах мира &ndash; машина
    <i> выводит </i> полезное поведение
            из любого изначально заданного. Универсальное обучение или самообучение
            - это обучение без внешней мотивации того, что и как надо учить. </p>

   <p> Достаточно легко проверяемое у машины отсутствие встроенных
            алгоритмов, приспособленных к определённому внешнему миру, является
            первой ступенью доказательства наличия субъективных, а не автоматических
            (алгоритмических, механических, конструктивно обусловленных) стремлений. </p>

   <p> О способностях машины мы будем судить по её
    <i> поведению </i> , так как невозможно объективно проверить наличие ощущений
            у другого субъекта. Доказательство возникновения сознания должно
            исходить из особенностей конструкции и из заключения скептически
            настроенного эксперта. Мы можем предлагать тесты и способы доказательства,
            но только независимый эксперт проверяет, что наша машина обладает
            сознанием. Он сам должен убедиться в том, что наша машина обладает
            творчеством, испытывает эмоции по поводу своих действий и нашего
            отношения к ней. </p>

   <h3> Направление поиска </h3>

   <p> Сознание человека реализовано победившими в эволюционной борьбе
            биологическими средствами. При другом стечении обстоятельств вместо
            нервной системы мы могли бы иметь несколько отличающуюся или совсем
            другую систему информационного обмена между органами, а вместо
            мозга - другой орган для централизованного управления организмом. </p>

   <p> Возможность функционального объяснения механизма научения
            предполагает, что одинаковые функции могут исполняться различными
            техническими средствами. Эта идея позволяет не ограничивать себя
            подражанием природе. В частности, не обязательно размещать в центре
            искусственного разума мозг из нейронных сетей, имитирующий живой
            мозг, если окажется, что без этого можно обойтись. В конце концов,
            природа создавала нас путём случайных попыток, и могла найти не
            самое оптимальное решение. </p>

   <p> Конечно, и я придумал не самый оптимальный алгоритм и требования
            к организации работы органов, обеспечивающих работу субъективного
            сознания. Это - один из возможных вариантов самообучающейся машины. </p>

   <p> Я попробую объяснить устройство ощущающего существа путём
            постепенной детализации задачи о построении самообучающейся машины.
            В какой-то момент множество деталей станет отвлекать от основной
            цели работы. Тогда нужно будет пропустить этап детализации, и
            перейти к обсуждению алгоритма и его реализации. </p>

   <p> Вместо постепенного введения существенных терминов и понятий,
            я буду использовать их с самого начала, и буду уточнять их значение
            только в силу необходимости их конкретного применения. Вы можете
            заметить противоречия в трактовке некоторых понятий. Считайте,
            что их определения сформулированы
    <i> в первом приближении </i> и ещё требуют согласования. </p>

   <p> К примеру, термины
    <i> прогноз </i> или
    <i> поведение, </i> используются как в обычном широком, так и в алгоритмическом смысле,
            и нужно выполнить плавный переход от одного понимания к другому.
            В алгоритме нет особой разницы между сенсорами и эффекторами.
            Поэтому прогнозирование относится как к поведению, так и к восприятию.
            Попробуйте объединить традиционно активное
    <i> поведение </i> и пассивное
    <i> ощущение </i> , и у вас сначала тоже возникнут
            противоречия. </p>

   <p> Почему я предпочитаю "сознание" традиционному понятию
            "искусственный интеллект"? Зачем называть кибернетическую
            систему существом? Не выдаю ли я желаемое за действительное? Как
            эти естественные вопросы, так и ответы ещё потребуют разъяснений. </p>

   <p> Значение термина "искусственный интеллект" зависит
            от контекста. Меня интересует та часть задачи, которая рассматривает
            возможность создания искусственного сознания, создания чувствующей
            и осознающей свои ощущения машины. О том, как сознание и интеллект
            развивается из ощущений рассказано в статье "
    <a href="../mind/consciousness.html">
     Механизмы сознания </a>
    " и на других страницах сайта. </p>

   <p> Я не могу обойтись без таких терминов, как сознание и ощущение
            ещё и потому, что разрабатываемый алгоритм не предназначен для
            решения определённой технической задачи ИИ, вроде идентификации
            почерка, распознавания текста, или "смыслового" поиска
            в базе данных. Алгоритм по существу не конкретен и вообще не задаёт
            никакой предписанной реакции на входные данные. </p>

   <p> Смысл подхода, совмещающего такие противоречивые понятия,
            как абстрактность и алгоритм, не удаётся объяснить чисто технически,
            без ссылок на философские и психологические аргументы. </p>

   <p> В частности, машину, имеющую субъективные ощущения, естественно
            называть существом. К этому слову нужно относиться как к основному
            требованию поставленной задачи. Что получится в результате &ndash; машина
            или существо &ndash; это тема отдельного исследования, которое само
            может изменить наши понятия о разуме в применении к машине. </p>

   <h3> Объективный внешний мир </h3>

   <p> Об уровне интеллекта и о возможных ощущениях машины можно
            судить только наблюдая и изучив её
    <i> поведение </i> , то есть
            взаимодействие с внешним миром, в том числе с нами. </p>

   <p> Обычное понятие поведения подразумевает заинтересованность
            в результате, а не просто взаимодействие. Строго говоря,
    <i> заинтересованность </i> является свойством субъекта и скрыта от стороннего наблюдателя.
            Она может проявиться через характерные признаки поведения. Эти
            признаки зависят от характера целевой функции, физических особенностей
            организма, особенностей
    <i> алгоритма </i> универсального обучения,
            (и от нашей способности к их интерпретации :). </p>

   <p> Для методического упрощения задачи можно дать машине искусственный
            внешний мир. Однако предопределённые рациональные свойства искусственного
            мира можно ошибочно принять за интеллектуальное достижение машины,
            так как иногда трудно отделить
    <i> поведение мира </i> от поведения
            существа в их взаимодействии. Поэтому в перспективе требуются
            испытания в реальном мире,
    <i> окружающем </i> и нас и наше искусственное
            существо. </p>

   <p> Свойства физического мира не зависят от меня, что особенно
            важно для беспристрастного испытания искусственного интеллекта.
            Объективность внешнего мира означает, что его свойства не зависят
            от сознания и от внутренней модели мира. </p>

   <h3> Сознание и тело </h3>

   <p class="center">
    <img alt="Рис.1 Мир и тело материально,
      а сознание не относится к физическому миру" height="237" src="images/al01.gif" title="Сознание идеально,
      но почему-то оно может влиять на физический мир. И, тем более,
      мир влияет на сознание." width="502"> </p>

   <p> Сознание не является физическим объектом и не имеет геометрической
            связи с физическим миром. Можно считать, что объективный мир является
            внешним по отношению к сознанию в том смысле, что сознание является
            частью
    <i> всего мира </i> (этот термин объясняется в статье "
    <a href="../world/space.html">
     <b> Происхождение пространства </b> </a>
    ").
    <i> Законы внешнего мира </i> не зависят от
            сознания, в то время как сознание зависит от мира и отражает его.
            Однако локальные свойства мира зависят от материализованной активности
            (сознательного) существа или машины. </p>

   <p> Физическое тело существа, обладающего сознанием, включая его
            мозг и прочие органы, является геометрически вложенным в мир.
            Можно говорить о внешнем или окружающем мире, как о части мира
            вне тела. </p>

   <p> Тело не обязательно имеет физическую форму, например, оно
            может быть
    <i> информационным </i> на физическом или на информационном
            же носителе. Тело такого эфемерного существа остаётся частью объективного
            мира и служит носителем органов, мозга и других систем, обеспечивающих
            работу сознания. </p>

   <p> В общем, понятие тела тоже условно, и используется здесь в
            качестве объединяющего названия для органов и системы управления,
            которые не обязаны геометрически находиться в пределах легко узнаваемого
    <i> физического организма </i> . </p>

   <p> Если существо имеет физическое тело, то у него могут быть
            внешние органы, взаимодействующие с внешним миром, и внутренние
            органы, определяющие (или влияющие на) внутренние физические параметры
            тела. Функционально, внутренние органы не отличаются от геометрически
            внешних органов и взаимодействуют с миром и друг с другом, физическими
            средствами. </p>

   <h3> Органы и мозг </h3>

   <p> Любое устройство, преобразующее воздействие в код, или код
            в воздействие, может служить органом-сенсором или исполнительным
            органом машины. Для обеспечения универсального обучения органы
            должны обладать особыми свойствами, которые имеются не у любого
            преобразователя. Оптимальная конструкция и особые функции датчиков-преобразователей,
            превращающие их в эффективные органы, следуют из разграничения
            доступа к объектам и данным между мозгом, органами и внешним миром,
            которое требуется для обеспечения универсальности мозга. </p>

   <p> Связь органов с внешним миром может быть физической или информационной
            в зависимости от природы этого мира. Связь материальных органов,
            посредством нервной системы, с материальным мозгом уже можно считать
            и физической и информационной, что соответствует современным представлениям
            о роли мозга в организме. </p>

   <p> Связь мозга с сознанием является не информационной, а
    <i> абстрактно-ассоциативной </i> . Субъект наблюдает внешний мир
            через калейдоскоп ассоциативной игры мозга с
    <i> хранящимся в </i> <i> памяти </i> прежним опытом взаимодействия мозга с органами
    <i> . </i> Субъективное наблюдение воспринимается субъектом, например
            человеком, а не его мозгом в виде форм сознания &ndash; образов, идей,
            ощущений. Для мозга идеальные ощущения - недоступная
    <i> абстракция </i> . </p>

   <p class="center">
    <img alt="Рис.2 Связь сознания с миром
      и органами тела ассоциативна" height="248" src="images/al02.gif" title='Связь сознания с миром ассоциативна
      и не конкретна. Многие "знания" о мире не содержатся
      в сознании, а всякий раз заново реконструируются при помощи самого
      внешнего мира.' width="531"> </p>

   <p> Сознание взаимодействует с миром при помощи органов, используя
            эту же
    <i> абстрактно-ассоциативную связь </i> . Физически взаимодействие
            происходит между органами и внешней по отношению к ним частью
            мира, в том числе и друг с другом, по общим законам взаимодействия
            частей мира. Сознание наблюдает это взаимодействие, интерпретируя
            его в своих идеальных категориях (ощущения, эмоции, идеи), и воспринимая
            себя субъектом, управляющим своим телом. О том, в каком смысле
            идеальное сознание включено в цепь физических взаимодействий,
            говорится в заметке "
    <a href="../mind/ideal.html">
     Детерминизм и свобода воли </a>
    ". </p>

   <h3> Универсальный мозг </h3>

   <p> Связь тело-сознание, в отличие от физической или информационной
            связи, не поддаётся формализации из-за своей абстрактности. Когда
            я пишу этот текст, то работаю с понятиями и символами. В это время
            мозг принимает и выдаёт нервные сигналы, а руки преобразуют нервные
            импульсы в движения. Понятия, нервные сигналы и движения связаны
            друг с другом только благодаря тому, что они направлены на взаимодействие
            с одним и тем же внешним миром. Они
    <i> отражают </i> один и тот
            же объективный мир, но имеют несводимую друг к другу внутреннюю
            природу. Используемая в работе универсального мозга формализация
            не может ссылаться на конкретные, представимые средствами сознания
            образы, например, понятия. И не может ссылаться на представимые
            средствами объективного мира внешние объекты, например, на изображения
            символов. </p>

   <p> "Неформализуемость основ формализма" является другим
            выражением несводимости материального и идеального, и имеет неконструктивный
            характер, то есть не препятствует построению универсального мозга
            и ощущающей машины и возникновению ощущающих существ в природе. </p>

   <p> Конструктивным следствием неформализуемости сознания является
            то, что его не нужно "формализовать" для обеспечения
            субъективных ощущений у машины. В частности, не нужно имитировать
            структуру внешнего мира в памяти. Не требуется хранить в памяти
            слова, планы лабиринта, распознаваемые изображения - достаточно
            хранить сигналы, которыми обменивались мозг и органы. </p>

   <p> В моём алгоритме, абстрактность мозга по отношению к текущему
            состоянию машины состоит в том, что он ассоциативно оперирует
            только прошлым опытом. В отличие от универсального мозга сознание
            воспринимает конкретное ощущаемое состояние (в контексте всего
            прошлого опыта) в форме образов взаимодействия с внешним миром.
            Текущее состояние может инициировать образы как прошлого (воспоминание),
            так и предполагаемого будущего (прогноз). </p>

   <h3> Специализированные органы </h3>

   <p> Органы, приспособленные к выполнению определённых физических
            преобразований, являются источниками ощущений (качеств внешнего
            мира) для сознания. </p>

   <p> Органы конкретны. Их функция преобразования воздействие-код
            не обязательно зависит от предыстории. Сознание менее конкретно.
            Оно интерпретирует своё текущее состояние, используя прошлый опыт.
            Мозг является абстрактным в том смысле, что он вообще не использует
            текущее состояние органов. </p>

   <p> Нервная система,
    <i> память </i> и мозг не имеют прямой связи
            ни с внешним миром, ни с сознанием. Для них физический мир так
            же эфемерен, как и сознание. Формализованная связь сознания с
            миром в форме мышления возникает на поздних этапах развития сознания. </p>

   <h3> Функции органов </h3>

   <p> Активность машины проявляется в действиях, поведении, зависящем
            от её состояния и от локальных свойств мира. Поведение осуществляется
            при помощи органов действия, исполнительных механизмов, которые
            мы назовём "эффекторами". Воспринимающие (пассивные)
            органы - это "сенсоры". </p>

   <p> Поскольку универсальный мозг не может хранить конкретные данные,
            то функция запоминания передаётся интерфейсу между мозгом и органами
            или самим органам. В последнем случае органы самообучающейся машины
            являются датчиками-преобразователями, способными накапливать в
            памяти последовательность кодов, выполнять некоторые функции по
            выбору данных из памяти, в частности, сравнивать текущие и прежние
            значения кодов. Такой орган, сам по себе, без обращения к мозгу,
            обладает когнитивными свойствами, так как имеет средства сравнения
            прежних и текущих данных. Орган даже может иметь свой информационный
            процессор - мозг. Использование централизованного мозга &ndash; это
            только один из способов организации кооперативной работы органов. </p>

   <p> Сенсоры измеряют доступные им свойства мира S(t) и преобразуют
            результат измерения в функцию-код s(t). S(t) - это не свойство
            мира в буквальном смысле, а то, что воспринимает сенсор &ndash;
    <i> состояние или показание сенсора. </i> </p>

   <p> Эффекторы преобразуют поток команд e(t) в действия по отношению
            к миру E(t). E(t) также является свойством или
    <i> состоянием </i> эффектора. </p>

   <p> Строго говоря, E(t) &ndash; это не само физическое действие, а то,
            что должен выполнить эффектор, если это позволят законы внешнего
            мира и текущее состояние эффектора. При успешном выполнении функцию
            E(t) можно трактовать, как само действие. При одном и том же состоянии
            эффектора E(t) физические действия могут различаться в зависимости
            от состояния мира. </p>

   <p> Органы взаимодействуют друг с другом как через внешние, реальные
            каналы связи E(t) -- &gt; S(t) (через внешний мир), так и через
            внутренние, информационные каналы s(t) -- &gt; e(t) (через систему
            управления). </p>

   <p> <b> Поведение </b> машины &ndash; это действия E(t) в зависимости
            от её состояния S(t). Обозначим поведение как преобразование S(t)
            -- &gt; E(t). Машине недоступны никакие другие сведения о мире,
            кроме тех, которые представимы через S(t). Действия E(t) тоже
            несут информацию о внешнем мире, хотя бы потому, что определённое
            состояние мира требует определённых действий. </p>

   <p> Воспринимаемое
    <b> поведение мира </b> E(t) -- &gt; S(t) определяется
            законами мира. Мы не конструируем мир и не интересуемся причинами
            определённого поведения мира. Может быть, мир тоже содержит свою
            "систему управления". </p>

   <p> При таком определении объект может иметь поведение
    <i> по
                отношению к миру </i> , а мир -
    <i> по отношению к опыту (внутреннему
                миру) объекта </i> .
    <i> Взаимодействие </i> происходит между
            конкретными объектами, а
    <i> поведение </i> &ndash; между одним объектом
            и всеми прочими объектами в мире, которые рассматриваются как
    <i> внешний мир </i> . При таком толковании термин "поведение",
            пока отличается от термина "заинтересованное поведение". </p>

   <p> Заинтересованное (умышленное, осознаваемое) поведение возникает
            в силу стремления машины оптимизировать заданную целевую
    <i> функцию
                состояния </i> W в условиях взаимодействия с реальным миром. </p>

   <p> Целевая функция W может формироваться специальными сенсорами
            Sw, анализирующими общее состояние системы. В общем случае можно
            вырабатывать сигнал W не путём прямого измерения, а путём расчёта
            по данным других датчиков W=W(S,E). При этом значения W(t) полностью
            определяются показаниями (кодами, сигналами) датчиков s(t) и e(t). </p>

   <h3> Система управления </h3>

   <p> <i> Система управления </i> самообучающейся машины состоит
            из
    <i> абстрактной </i> части, которая оперирует с
    <i> ассоциациями </i> <i> по поводу </i> s(t) и e(t), и интерфейса с органами,
            который работает с конкретными кодами s(t) и e(t). </p>

   <p> Если бы система управления была основана "на правилах",
            и выполняла только заранее определённые операции с функциями s(t)
            и e(t), то она не имела бы возможности
    <i> универсального </i> обучения. Правила можно изменять по мере накопления опыта. Но
            проще построить универсальный мозг - ядро системы управления,
            вообще не работающее с функциями s(t), e(t). </p>

   <p> Разделение системы управления на систему взаимодействия с
            органами и универсальный мозг приводит к возможности замены органов
            или замены содержания их памяти, то есть кодов s(t) и e(t), без
            замены алгоритма функционирования универсального мозга машины.
            В том числе, возможна частичная замена или модернизация органов
            без перерыва сознания. </p>

   <p> Иерархически каждый орган может обладать своими органами и
            мозгом. При этом конструкция существа представляет собой симбиоз
            взаимодействующих органов, для которых также заданы внутренние
            правила обмена информацией. Однако "правила" физического
            взаимодействия определяются законами мира и не могут быть заданы
            произвольно. При таком подходе каждый живой нейрон является "органом",
            совмещающим функции сенсора и эффектора. </p>

   <h3> Взаимодействие блоков </h3>

   <p> Сенсоры выполняют конкретное преобразование S(t) -- &gt; s(t),
            которое можно интерпретировать как преобразование воздействия
            со стороны мира в код. Эффекторы выполняют конкретное преобразование
            e(t) -- &gt; E(t), то есть преобразуют код команды в воздействие
            на мир. Преобразование s(t) -- &gt; e(t) (
    <i> поведение </i> системы управления) выполняет система управления. </p>

   <p> Формат данных и сами величины s(t) и e(t) зависят от устройства
            датчиков. Эти данные остаются в их памяти, но не зависят, не контролируется
            и никак не используется мозгом. У нашей машины
    <i> мозг </i> и
    <i> память </i> не объединены в один блок, подобный биологическому
            мозгу. Абстрактная часть системы управления - мозг не обрабатывает
            сигнал s(t) и не вырабатывает сигнал e(t). </p>

   <p> Множество значений s(t) и e(t) для всех датчиков в определённый
            момент времени t называется событием Ev(t).
    <i> Событие </i> &ndash;
            это внутреннее представление данных, а не объективное явление.
            Если память принадлежит датчикам, то параметр t в Ev(t) имеет
            смысл момента времени в прошлом, а не текущего времени, как в
            функциях состояния сенсоров S(t) и эффекторов E(t). Множество
            данных s(t) и e(t) &ndash; это фиксированное, сохранённое в памяти
    <i> прошлое </i> . Поэтому полезно ввести два обозначения для времени:
            t &ndash; текущее время, tp &ndash; ссылка на момент времени в прошлом. </p>

   <p> Непрерывная последовательность событий, все из которых были
            похожи на текущее событие в течение некоторого времени до данного
            момента t, и которая завершается событием, похожим на текущее
            событие Ev(t), называется узнаваемым
    <i> процессом. </i> Процесс
            &ndash; это событие вместе со своей историей. </p>

   <p> Датчики сообщают мозгу свои функции узнавания Ct(tp) (где
            t &ndash; текущее время, tp &ndash; все моменты прошлого). Функция узнавания
            показывает, в какие из прошедших моментов времени события Ev(tp)
            были похожи на текущее событие Ev(t). Функции Ct(tp) не содержат
            информации о том, что и в каком виде было зафиксировано датчиком. </p>

   <p> В ответ мозг сообщает датчикам моменты прошлого tps, когда
            узнавание было
    <i> удачным </i> для системы в целом.
    <i> Удачное
                узнавание </i> - это такой
    <i> похожий </i> момент tp в прошлом,
    <i> после которого </i> была снижена потребность W. </p>

   <p> <i> Похожесть </i> или
    <i> узнавание </i> определяется при
            сравнении событий или процессов, а
    <i> удачность </i> узнавания
            &ndash; при сравнении величин W, зарегистрированных после узнавания. </p>

   <p class="center">
    <img alt="Рис.2а Графики событий, узнавания
      и потребности в памяти" height="443" src="images/al02a.gif" title='Пример согласованных по времени
      зависимостей успеха, узнавания, целевой функции "желания".' width="409">
    <br> На рисунке: Текущее состояние s(t) похоже на некоторые сохранённые
            в памяти состояния. После моментов tps1 и tps2 было замечено уменьшение
            потребности W. </p>

   <p> Датчики-преобразователи машины, способной к универсальному
            обучению, можно по праву назвать органами, так как они могут обучиться
            чему угодно в пределах своих физических способностей, что было
            бы невозможно при заранее заданном алгоритме управления датчиками. </p>

   <p> Органы сами хранят свой опыт. Поэтому после обучения шаблоны
            правильного поведения остаются в памяти органа, что разгружает
            мозг от "квалифицированного" управления. Другими словами,
            по мере обучения мозг не умнеет и не накапливает знания. </p>

   <p> Разумность поведения и способности к обучению нашего существа
            зависят от эффективности органов и от того, как организовано внутреннее
            информационное взаимодействия между органами. И хотя органы могут
            иметь непосредственную зависимость друг от друга, в том смысле,
            что сигнал s
    <sub> i </sub> (t) органа i является командой e
    <sub> j </sub> (t) = f [s
    <sub> i </sub> (t)] для органа j, мы не будем
            рассматривать такие чисто
    <i> безусловные рефлексы </i> . </p>

   <p> Система управления вырабатывает команды e(t), основываясь
            на данных s(t) и на прежнем опыте машины. Такая система управления
            взаимодействует с органами и не взаимодействует с внешним миром.
            Возможный датчик состояния W самой системы управления или мозга,
            вырабатывающий соответствующий сигнал s(t), функционально является
            органом, а не частью системы управления. </p>

   <p class="center">
    <img alt="Рис.3 Между сенсорами и эффекторами
      находится Система управления" height="333" src="images/al03.gif" title="Традиционная схема преобразования
      входящих данных в исходящие действия." width="333"> </p>

   <p> Потоки данных s(t) и e(t) скрыты от абстрактной части системы
            управления - мозга. Сенсоры и эффекторы образуют собой интерфейс
            между миром и системой управления. А между мозгом и датчиками
            должен быть интерфейс преобразующий "прошлое" tp в "настоящее"
            t. </p>

   <p class="center">
    <img alt="Рис.4 Внутри системы управления
      между сенсорами и эффекторами находится Мозг." height="333" src="images/al04.gif" title="В традиционной
      схеме мозг является системой управления для системы управления
      телом." width="334"> </p>

   <p> Хотя я отделяю систему управления от других органов, но её
            можно считать особым органом, регулирующим общее состояние системы.
            Также и мир можно считать органом &ndash; генератором или источником
            возможных состояний системы, измеряемых сенсорами S(t). </p>

   <p> Сенсор воспринимает сигнал S(t) и вырабатывает сигнал s(t).
            Он преобразует своё состояние S(t) в код s(t). </p>

   <p> Система управления (СУ) воспринимает сигнал s(t) и вырабатывает
            сигнал e(t). Здесь уже видно, что s(t) &ndash; это не совсем "текущее"
            состояние СУ, так как СУ использует всё хранимое в памяти прошлое
            для выработки сигнала e(t). </p>

   <p> Точно так же есть зависимость от прошлого у состояний мира,
            сенсоров и эффекторов. </p>

   <p> Эффектор воспринимает сигнал e(t) и вырабатывает сигнал E(t).
            Текущим состоянием E(t) можно считать физическое состояние эффектора,
            а e(t) является его информационным состоянием. </p>

   <p> Мир воспринимает сигнал E(t) и вырабатывает сигнал S(t). Мир
            преобразует задаваемое машиной состояние E(t) в доступный восприятию
            машины
    <i> физический код </i> S(t). Цикл преобразований замыкается,
            и мы получаем круговую диаграмму - другое представление схемы
            3. </p>

   <p class="center">
    <img alt="Рис.5 Круговая схема - Мир -
      сенсоры - система управления - эффекторы" height="303" src="images/al05.gif" title='Равноправная
      круговая схема "круговорот данных".' width="540"> </p>

   <p> Заметим, что все части этой схемы принадлежат миру, и она
            не требует никакого "сознания". Функционирование мозга
            тоже не нуждается в наличии сознания. Круговая схема показывает,
            что в схеме машины каналы сенсора и эффектора размещены симметрично
            относительно друг друга, и даже дублируют друг друга. Из рис.4
            и рис.5 видно также, что мир и мозг расположены симметрично по
            отношению к блоку из тела и системы управления. </p>

   <p class="center">
    <img alt="Рис.6 Круговая схема с деталями
      Системы управления" height="362" src="images/al06.gif" title="Сенсоры и эффекторы являются физическими
      устройствами, а их память и мозг - информационными." width="494"> </p>

   <p> Обведённую пунктирной рамочкой
    <i> систему управления </i> по аналогии с биологическим мозгом можно было бы тоже назвать
    <i> мозгом </i> , но мы сохраним это название для
    <i> центра абстрактного
                управления </i> , который выполняет только часть функций настоящего
            мозга. Я не объединяю CPU (центральный процессор) и память в единое
            устройство "модель живого мозга", и даже не стану использовать
            далее слова "система управления", так как считаю важным,
            чтобы "память" принадлежала органам и была не видна
            из центра
    <i> абстрактного </i> управления. </p>

   <p> На рисунке 6 уточнено, что поток данных между мозгом и интерфейсом
            эффектора должен быть двунаправленным, так как мозг может получать
            ассоциативную информацию Ct(tp) не только о состоянии сенсоров,
            но и о состоянии эффекторов. </p>

   <p> Мир, сенсоры и эффекторы выполняют прямое преобразование "по
            правилам", а мозг решает косвенную задачу оптимизации совокупности
            физических состояний датчиков S(t) и E(t), не используя данных
            s(t) и e(t). </p>

   <p> Для мозга сенсор практически не отличим от эффектора. Если
            бы мозг подавал команду tps также и на сенсор, то в этой структурной
            схеме сенсор и эффектор можно объединить в одно двунаправленное
            устройство "датчик", интерфейс которого </p>

   <ul> <li> получает от мозга
     <i> команду </i> tps, извлекает из памяти
                данные d(tps) (то есть, s(tps) или e(tps)), и подаёт на датчик
                команду d(t)=d(tps) </li>
    <li> получает от датчика и направляет в память команду d(t), то
                есть просто фиксирует состояние датчика в момент t, </li>
    <li> извлекает из памяти все d(tp), формирует и передаёт мозгу
                данные об узнавании Ct(tp). </li> </ul>
   <p> Объединяя сенсор и эффектор в единое устройство "датчик",
            мы включаем в него как физические свойства взаимодействия с миром,
            так и функцию интерфейса с мозгом и память. Это и есть "орган"
            содержащий свой интерфейс для взаимодействия с мозгом. </p>

   <p class="center">
    <img alt="Рис.7 Круговая схема для данных
      при соединении элементов в цепочку" height="201" src="images/al07.gif" title="Симметричная схема,
      в которой мозг и внешний мир имеют равноправный доступ к памяти." width="626">
    <br> На рисунке:
    <i> Орган </i> содержит физический интерфейс,
            память и информационный интерфейс. </p>

   <p> Возможны разные реализации универсальной адаптирующейся машины,
            которая оптимизирует заданную целевую функцию. Подробности устройства
            мозга, памяти, да и самой целевой функции не имеют принципиального
            значения. Для развития сознания достаточно, чтобы у машины имелись
    <i> мотивы </i> , а не алгоритмы поведения. Сознание развивается
            из ощущений, а не из физической реализации. </p>

   <h3> Проследим путь данных </h3>

   <blockquote>
    <p> В физическом мире происходит взаимодействие органов с миром,
                а в сознании происходит ассоциативное возбуждение воспоминаний
                о прежних ощущениях. Оба этих мира находятся вне информационной
                системы управления нашей машиной. </p>
   </blockquote>

   <p> Физические данные превращаются в информацию в датчике-преобразователе
            (сенсоре и эффекторе). </p>

   <p> В момент t датчик вырабатывает код d(t), соответствующий его
            текущему состоянию D(t). </p>

   <p> Код d(t) подаётся на вход памяти датчика. В память заносятся
            коды состояния датчиков d(t), а также численное значение целевой
            функции W(t), которое вычисляется на основе текущих состояний
            датчиков. </p>

   <p> На основе данных d(tp)
    <i> информационный интерфейс </i> вырабатывает
            функцию Ct(tp), имеющую смысл сравнения текущего процесса со всеми
            данными, ранее попавшими в память в моменты tp&lt;t. </p>

   <p> Функция Ct(tp) поступает в мозг, который сопоставляет все
            такие функции от всех органов, и находит, какие из моментов прошлого,
            похожи на текущий момент одновременно у многих органов. В эти
            моменты некое суммарное значение Ct(tp) максимально. Из всех похожих
            моментов мозг выбирает наиболее успешные моменты tps, которые
            в прошлом привели к последующему лучшему значению целевой функции
            W. Данные из канала W доступны мозгу в виде сравнимых чисел. </p>

   <p> Моменты tps могут различаться для разных групп датчиков. Благодаря
            этому мозг способен подобрать такой лучший момент в прошлом, который
            синтезирован из различных фрагментов истории, и который лучше
            соответствует текущей ситуации, чем любая из ситуаций, хранимых
            в памяти. </p>

   <p> Получив от мозга значение момента времени tps, память (датчика)
            выдаёт на датчик код его состояния d(t)=d(tps) в этот момент. </p>

   <blockquote>
    <p> Именно этот
     <i> синтезированный </i> мозгом момент прошлого
                (не всегда совпадающий с текущим моментом и с реальным прошлым)
                может стать текущим осознаваемым ощущением, так как он строго
                ассоциативно привязан к осознанным ощущениям или осмысленным понятиям,
                то есть, он имеет смысл. Практически, позитивный опыт существования
                в физическом мире приводит к тому, что почти все текущие ощущения
                уже были испытаны ранее и способны быть осознаваемыми. </p>
   </blockquote>

   <p> Сенсор игнорирует эту команду, а эффектор выполняет соответствующее
            действие по отношению к миру. </p>

   <p> Эффекторы можно устроить так, что тот же самый, неизменённый
            код команды d(t) является подтверждением её успешного выполнения.
            Выполненная команда и есть
    <i> код состояния </i> эффектора. Если
            команда была некорректной или что-то другое помешало её исполнению,
            то эффектор может оказаться в другом состоянии. В этом случае
            входная и выходная команды различаются. </p>

   <p> Новый цикл обработки данных начинается с поступления состояний
            датчиков в память. Буквальное последовательное исполнение этого
            цикла не обязательно, так как, благодаря привязке к общему времени
            все компоненты машины могут работать асинхронно. </p>

   <h2> Структура данных </h2>

   <p> Описанные выше системы самообучающейся машины, в конце концов,
            обрабатывают
    <i> данные </i> . Математическое описание этой обработки
            не требует разделения машины на органы, разграничения их функций,
            не требует упоминания того, что
    <i> данные хранятся в памяти </i> и других подобных ссылок на устройство машины. Даже представления
            о
    <i> времени </i> и о
    <i> работе в реальном времени </i> относятся
            не к алгоритму, а к его применению. </p>

   <p> Однако я буду использовать привязку обозначений и операций
            к машине, чтобы уменьшить формальность довольно непрозрачного
            и усложнённого (на первый взгляд) алгоритма. </p>

   <h4> Данные </h4>

   <p> Итак, имеются
    <i> данные </i> <span class="formula big">
     di(t) </span> , где i &ndash; номер датчика &ndash;
    <i> источника данных </i> ,
            t &ndash; время. Параметр
    <i> время </i> используется для синхронизации
            выбора данных из памяти независимо работающих датчиков. Синхронность
            хранения данных можно обеспечить тем, что метка времени заносится
            в память датчика в момент поступления данных, или путём одновременного
            считывания данных всех датчиков в заданные моменты времени. Этот
            вопрос относится к реализации алгоритма. </p>

   <p> В текущий момент времени t=tc величина di(t) принимает значение
    <i> текущего </i> <i> состояния датчика </i> i. Для t &gt;tc данные
            могут задаваться путём ссылок на моменты времени
    <i> в прошлом </i> t&lt;tc, например </p>

   <p class="formula big center">
    d(t2) &larr; d(t1), t2&gt;tc, t1&lt;tc </p>

   <p> Такое
    <i> упреждающее </i> задание данных имеет смысл
    <i> прогноза </i> : в момент t2 ожидается поступление таких же данных,
            как данные, полученные в момент t1. </p>

   <p> При t&lt;tc данные не изменяются. Они просто
    <i> хранятся
                в памяти </i> . </p>

   <h4> Целевая функция </h4>

   <p> Целевую функцию
    <i> удовольствия </i> P(t) может вырабатывать
            специальный датчик. В качестве алгоритмической реализации такого
            датчика можно выполнять вычисление функции P(t) в момент поступления
            данных t=tc.
    <i> Текущее удовольствие </i> P(tc) - это не функция
            над содержимым памяти, а функция текущего состояния датчиков. </p>

   <p class="formula big center">
    P (tс) = f [ d1(tс), d2(tс), &hellip;
            ] </p>

   <p> Функция
    <i> удовольствия </i> P противоположна функции
    <i> потребности </i> W. Мозг нашей машины должен обеспечить максимальное
            среднее значение P(t). Среднюю величину P(t) в интервале времени
            от tc до tc+T назовём
    <i> предстоящим успехом </i> S(t). </p>

   <p class="formula big center">
    S(t) = 1/T
    <span class="big">
     <span class="big">
      &int; </span> </span> P(t)dt </p>

   <h4> Узнавание </h4>

   <p> Данные различных датчиков несопоставимы, так как они могут
            обслуживать органы, имеющие разную физическую природу. Возможно
            только сравнение состояний одного датчика, зарегистрированных
            в различные моменты времени. Величина
    <i> функции сравнения </i> Ci(t1,t2) пропорциональна
    <i> похожести </i> данных, сохранённых
            в памяти датчика i в моменты t1 и t2. </p>

   <p class="formula big center">
    0 &le; Ci (t1, t2) &le; 1 </p>

   <p> Если di(t1) = di(t2), то Ci (t1, t2) = 1. Данные в моменты
            t1 и t2 считаются похожими, если Ci (t1, t2) &ge; C0, где C0:
            0 &lt; C0 &le; 1 -
    <i> порог узнавания </i> . К примеру, C0=0.5.
            В момент t1 данные первого датчика d1(t1) похожи на текущие данные
            d1(tc), если C1(t1, tc) &ge; C0. </p>

   <h4> Процесс </h4>

   <p> <i> Процессом </i> t1 называется участок данных di(t), включающий
            точку t1. Для обозначения процесса используется ссылка на момент
            времени t1. К этому моменту процесс продолжается, (то есть, обычно,
            узнаётся) уже некоторое время. Сравнение процессов характеризуется
    <i> историей </i> Hi </p>

   <p class="formula big center">
    Hi (t1, t2) = max(h) </p>

   <p> где h - это продолжительность совпадения процессов: Ci (t1-&Delta;t,
            t2-&Delta;t) &ge; C0, &Delta;t = 0 ... h </p>

   <p> <i> История </i> &ndash; это время, в течение которого сравниваемые
            процессы были
    <i> похожими </i> . </p>

   <h4> Группа датчиков </h4>

   <p> Для проверки одновременного узнавания процессов, сохранённых
            в памяти нескольких датчиков, используется
    <i> группа (множество)
                датчиков </i> </p>

   <p class="formula big center">
    Mj = [ i1, i2, &hellip;, iJ ] </p>

   <p> i1, i2 &hellip; - номера датчиков, входящих в данную группу. </p>

   <p> Сравнение в группе Mj определяется наиболее короткими процессами.
            Если узнавания нет хотя бы у одного датчика, то узнавания нет
            и в группе. </p>

   <p class="center">
    <span class="formula big">
     Hj (t1, t2) = min
                [ Hi (t1, t2) ], i </span> из
    <span class="formula big">
     Mj </span> </p>

   <p> Мы будем использовать индекс j для обозначения номера группы
            датчиков, и индекс i для обозначения индивидуального датчика. </p>

   <h4> Критерий узнавания </h4>

   <p> Группа Mj вместе с приписанным к ней
    <i> порогом истории </i> hj называется критерием узнавания. </p>

   <p class="formula big center">
    Aj = ( Mj, hj ) </p>

   <p> Процессы t1 и t2 похожи по критерию Aj, если Hj (t1, t2) &ge;
            hj. Процесс t1
    <i> узнаётся </i> , то есть, он похож на текущий
            процесс tc, если хотя бы для одного из
    <i> заданных </i> критериев
            узнавания </p>

   <p class="formula big center">
    Hj (t1, tc) &ge; hj </p>

   <p> Все найденные в памяти процессы, которые узнаются по критерию
            Aj, назовём
    <i> списком узнаваемых процессов </i> или
    <i> списком
                Aj </i> . </p>

   <h4> Варианты продолжения текущего процесса </h4>

   <p> Для всех Nj процессов t1, t2, &hellip;, узнаваемых по критерию Aj
            можно рассчитать средний предстоящий успех </p>

   <p class="formula big center">
    Sj = [ S(t1) + S(t2) + &hellip; ] / Nj </p>

   <p> В статистическом смысле этот успех зависит от прошлого t &lt;
            tс и от начального участка будущего t: tc &le; t &lt; tc+T. Узнаваемые
            по Aj процессы могут иметь различное будущее. </p>

   <p> Разделим процессы Aj по вариантам будущего в пределах tc &hellip;
            tc+dt. Для этого найдём все процессы, которые в интервале от tc
            до tc+dt похожи (по критерию Aj) на первый процесс t1 из
    <i> списка
                процессов Aj </i> . Затем, среди оставшихся процессов найдём все
            процессы, похожие в момент tc+dt на первый из оставшихся процессов.
            И так далее, до исчерпания списка узнаваемых процессов. Чем меньше
            глубина прогноза dt, тем меньше различных вариантов будущего будет
            обнаружено. </p>

   <p> Допустим, всего найдено K вариантов продолжения текущего процесса,
            которые можно обозначить ссылками на моменты времени t1, t2, &hellip;
            tK. Отдельные экземпляры процесса tk обозначим вторым индексом:
            tk1, tk2, &hellip; Для каждого варианта tk рассчитаем предстоящий успех </p>

   <p class="formula big center">
    Sk = [ S(tk1) + S(tk2) &hellip; ] / Nk </p>

   <p> где Nk &ndash; число экземпляров варианта k. </p>

   <p> Также можно оценить дисперсию определения средней величины
            успеха Sk </p>

   <p class="formula big center">
    Dk = { [S(tk1)-Sk]
    <sup> 2 </sup> + [S(tk2)-Sk]
    <sup> 2 </sup> + &hellip; } / Nk
    <sup> 2 </sup> </p>

   <p> В знаменателе стоит квадрат длины выборки, так как мы определяем
            не дисперсию успеха, а
    <i> дисперсию средней величины </i> успеха.
            Дисперсия отличается от нуля из-за конечности длины выборки. Таким
            образом, мы определили варианты прогноза развития процесса Aj,
            ожидаемый успех каждого варианта Sk, и точность оценки этого успеха
            Dk. </p>

   <h4> Выбор более успешного варианта </h4>

   <p> Для двух прогнозов Sk1 и Sk2, основанных на двух вариантах
            будущего, рассчитаем
    <i> разрешение </i> R(1,2), которое характеризует
            статистическую надёжность того, что величины Sk1 и Sk2 различаются. </p>

   <p class="formula big center">
    R (1, 2) = (Sk1-Sk2) / sqrt(Dk1+Dk2) </p>

   <p> Если R(1,2) &ge; R0, то прогноз k1
    <i> достоверно </i> <i> успешнее </i> , чем прогноз k2. Величина R0 &ndash; это среднеквадратичный
    <i> порог разрешения </i> . Например, R0=1. </p>

   <p> <i> Разрешением </i> Rj критерия Aj считается лучшее из разрешений
            R (k1, k2), найденное для всех пар прогнозов </p>

   <p class="formula big center">
    Rj = max [ R (k1, k2) ], k1 &le;
            K, k2 &le; K </p>

   <p> Если Rj &lt; R0, то критерий Aj не принимается во внимание
            при поиске прогноза. Это один из способов отсева многочисленных
            критериев узнавания, среди которых нужно использовать наиболее
            достоверные. Отбор правильных критериев - отдельная не простая
            задача. </p>

   <p> Максимально успешный вариант продолжения текущего процесса,
            определённый по критерию Aj, назовём
    <i> предлагаемым прогнозом </i> . </p>

   <p> Можно доказать, что если критерий A1 шире, чем критерий A2
            (то есть группа M1 содержит группу M2, и h1 &ge; h2) то прогноз,
    <i> предлагаемый </i> A1 не хуже, чем прогноз A2. Есть и другие
            способы уменьшить число надёжных критериев
    <i> выбора поведения </i> . Нужное поведение реализуется при
    <i> исполнении </i> датчиками
            наиболее
    <i> выгодного прогноза </i> , отличающегося максимальным
            (с точностью до разрешения) ожидаемым успехом. </p>

   <h4> Синтез выгодного процесса, которого нет в памяти </h4>

   <p> Описанная структура данных и способ выбора наиболее успешного
            прогноза позволяет синтезировать действие, которое не встречалось
            ранее, и, предположительно, является более выгодным, чем все имеющиеся
            в памяти действия. </p>

   <p> Если достоверные критерии A1 и A2 предлагают одинаковый прогноз
            для общей подгруппы датчиков M1 и M2 или не содержат общих датчиков,
            то для датчиков M1 нужно выбрать действия, предлагаемые критерием
            A1, а для датчиков из группы M2 нужно выбрать действия, предлагаемые
            критерием A2. </p>

   <p> В силу независимости прогнозирования по критериям A1 и A2,
            эти действия могли ранее никогда не встречаться одновременно. </p>

   <p> Возможность одновременного исполнения нескольких процессов,
            сохранённых в памяти в разное время, обеспечивает прохождение
            этим алгоритмом
    <i> <a href="../mind/consciousness.html#selfawaretest">
      теста на
                    осознавание себя </a> </i> . </p>

   <p> *** </p>

   <p> Далее можно показать, каким образом данный алгоритм, обслуживая
            достаточно эффективные органы, обеспечивает обучение вплоть до
            долговременного запоминания и формирования
    <i> знаковой системы </i> без использования особой
    <i> долговременной </i> или
    <i> структурированной памяти </i> . Многие из интересных вопросов
            уже рассмотрены на страницах этого сайта. </p>

   <p> <a href="../post/email.html" rel="author" title="email и копирайт">
     Евгений Корниенко </a> </p>

   <p> 2001-08 </p>
  </main>

  <div id="menu">
  </div>

  <div class="foot1 ref">
   <p> <a href="../files/synt-2003-09.zip">
     synt.zip </a>
    Код на Delphi,
    <a href="../files/tmpbrain-2003-09.zip">
     tmpbrain.zip </a>
    Самообучающаяся бабочка </p>
  </div>

  <div class="foot1">
   <div class="cr">
   </div>
  </div>

  <div class="foot1 sel" data-id="algorithm" data-url="https://cord70.github.io/cyber/ai/algorithm.html" id="disqus_thread">
  </div>

  <footer>
  </footer>

  <noscript>
   <div>
    
   </div> </noscript>
 </body>
</html>