<!DOCTYPE html>
<html lang="ru">
 <head>
  <title> Искусственное сознание (для робота) </title>
  <meta content="Если неожиданный благоприятный результат получен чисто интеллектуальным путём, то такую радость мы воспринимаем, как чувство юмора." name="description">
  <meta content="искусственный, обучение, ощущение, самообучение, творчество, тест Тюринга, " name="keywords">
  <meta content="Евгений Корниенко" name="author">
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1" name="viewport">
  <link href="https://cord70.github.io/cyber/ai-post/ai.html" rel="canonical">
  <link href="https://cord70.github.io/cyber/favicon.svg" rel="icon" sizes="any" type="image/svg+xml">
  <link href="../images/main.css" rel="stylesheet">
  <script defer="" src="navAIpost.js"> </script>
  <script defer="" src="../images/ansimeta.js"> </script>
 </head>
 <body>

  <header>
  </header>

  <main>
   <p class="headquote">
    Придумывание и использование терминов входят
            в функции сознания и не отражаются в структуре мозга. Слепая эволюция
            не могла предусмотреть, о чём вы будете рассуждать. </p>

   <nav class="right">
    <p> Содержание: </p>

    <ul> <li> <a href="#BM12">
       Re: Что есть ИИ </a>
      <br> 2000-02-03 </li>
     <li> <a href="#BM5">
       Re: взгляд </a>
      <br> 29 июня 1999 г. </li>
     <li> <a href="#BM6">
       Re: взгляд </a>
      <br> 24 июня 1999 г. </li>
     <li> <a href="#BM4">
       Re: Вера и ИИ </a>
      <br> 11 марта 1999 г. </li>
     <li> <a href="#BM8">
       Re: Вера и ИИ </a>
      <br> 10 марта 1999 г. </li>
     <li> <a href="#BM3">
       Математика &amp; Физика </a>
      <br> 1998-10-28 </li>
     <li> <a href="#BM10">
       Re: Изменение </a>
      <br> 24 июля 1998 г. </li>
     <li> <a href="#BM9">
       Способность обучаться </a>
      <br> 1998-05-31 </li>
     <li> <a href="#BM2">
       Механизм предвидения </a>
      <br> 1998-05-22 </li>
     <li> <a href="#BM1">
       Re: Спасибо, alys! </a>
      <br> 16 ноября 1997 г. </li> </ul>
   </nav>

   <h2> Искусственное сознание </h2>

   <p id="BM12">
    <b> Re: Что есть ИИ </b> </p>

   <p> 2000-02-03 22:17 Конференция "Механизмы сознания" </p>

   <p> Muravjov Artem ( muravjoff@mtu-net.ru ) пишет </p>

   <p> <i> &gt; какое отношение к железу имеют термины "тонкие органы",
                "сила воли", "свобода воли", "заинтересованность", "душа" т.е.
                все ли участники дискуссии понимают в смысле железа под этим одно
                и то же ? </i> </p>

   <p> Конечно, каждый понимает эти термины по-своему. Смысл, который
            вкладывает в знакомые слова ваш собеседник, проясняется постепенно.
            Со временем живость ума и убедительность аргументов могут привести
            к сближению позиций. Но это необязательно. Беседа хороша уже
            тем, что я могу узнать, как относятся к моим идеям другие, и достаточно
            ли ясно я их излагаю. Если не ясно и не убедительно, то, может
            быть, я сам не очень понимаю о чём говорю, и над этими идеями
            нужно поработать. </p>

   <p> В том письме: </p>

   <p> Тонкие органы - это такие датчики и исполнительные механизмы,
            которые могут достаточно подробно взаимодействовать с внешним
            миром. </p>

   <p> Сила воли, свобода воли и заинтересованность - это понятия,
            которые достоверны для первой персоны. Для обоснования этих понятий
            требуется ссылка на собственный опыт, и недостаточно логических
            умозаключений из наблюдений над поведением
    <a href="../mind/consciousness.html#person1e3">
     третьей персоны </a>
    . </p>

   <p> Душа - это ненаучное слово обозначает способность к ощущениям,
            которую обнаруживает у себя первая персона. Душа или сознание
            - это то, что отличает субъекта от "бездушной" вещи. </p>

   <p> Какое отношение эти понятия имеют к железу? Если это бездушная
            машина (что требуется доказать или опровергнуть), то - никакого.
            А если это
    <a href="../mind/feel.html#BM2">
     чувствующая машина </a>
    (например,
            человек), то эти и другие атрибуты первой персоны могут характеризовать
            её переживания. </p>

   <p> Небольшая проблема состоит в том, что такие слова как "память",
            "интеллект", "чувствительность", и даже "желания" применяются
            в качестве технических терминов в отношении достаточно продвинутой
            техники. Ничего страшного в этом нет. Слова часто имеют несколько
            значений. </p>

   <p> &gt; &gt; вы считаете эмоции объективным параметром управления. </p>

   <p> <i> &gt; А у вас другое понимание ? </i> </p>

   <p> Да. Эмоции - это чувства, которые испытывает ощущающее (т.е.
            обладающее сознанием) существо. Эмоции являются внутренними побудительными
            мотивами для того или другого поведения. </p>

   <p> Внешние (объективные) проявления эмоций - это уже фрагменты
            поведения, по которым мы судим о наличии эмоций у субъекта. </p>

   <p> Источником эмоций могут быть состояние организма, химический
            состав, механические нагрузки и прочие объективные (измеряемые)
            вещи. Источниками эмоций могут быть и субъективные переживания,
            идеи. В обоих случаях - это некоторые "источники", причины, а
            не сами эмоции. Сами испытываемые эмоции не являются объективными
            "параметрами". </p>

   <p> <i> &gt; Я бы удовлетворился И на уровне Эллочки-людоедочки-домохозяйки
                :) Т.е. универсальный решатель бытовых задач с пониманием бытового
                человеческого языка. </i> </p>

   <p> "Универсальный решатель" каких-нибудь задач не удовлетворится
            пониманием бытового языка. Он будет совать нос туда, куда вам
            не захочется. Наверно, вас бы устроила
    <a href="../mind/prove.html">
     машина, выполняющая стандартные
                хозяйственные работы, </a>
    но, боже упаси, только без всякого
            творчества! </p>

   <p> <i> &gt; Что есть мотивация ? Не что иное как такая модификация
                нейронной сети, что она эволюционирует к состоянию с наим. "энергией".
                т.е. к удовлетворению этой "потребности". </i> </p>

   <p> Объективную физиологическую потребность можно назвать "объективной
            мотивацией". Это некоторая целевая функция, к которой стремится
            ЦНС. Слово "энергия" тут совершенно ни при чём. </p>

   <p> А есть сознательная "мотивация" - самооправдание своего действия.
            В применении к третьей персоне мотивация - это убеждение или подталкивание
            к определённому действию. </p>

   <p> Все три понятия логически связаны. Сознательная мотивация
            или формирование целенаправленного поведения обычно происходит
            для удовлетворения внутренней объективной, и поэтому часто неосознаваемой,
            потребности. Это можно проследить по поведению животных (но не
            человека :). </p>

   <p id="BM5">
    <b> Re: взгляд
     <br> </b> 29 июня 1999 г. 22:46 fido7.ru.ai </p>

   <p> Iskhakov Alex пишет </p>

   <p> &gt; &gt; Объективные данные не воспринимаются непосредственно
            и изолированно от предшествующего опыта, а постоянно встраиваются
            в картину того, что должно быть </p>

   <p> <i> &gt; т.е. происходит сравнение того что есть с тем что
                должно быть? </i> </p>

   <p> Осознавание поступивших данных у человека наступает примерно
            через 0.2 секунды, когда эти данные технически уже перешли в разряд
            "прошлого опыта" и глаз уже воспринимает новую информацию. У животных
            с менее развитым сознанием это время меньше, так как сигнал проходит
            через меньшее количество "ассоциативно важных" зон мозга прежде,
            чем будет выработана реакция или хотя бы осознавание этого сигнала.
            Время реагирования самих колбочек 0.001 секунды. </p>

   <p> Поэтому не совсем верно считать, что происходит сравнение
            непосредственных данных с тем, что должно быть, то есть с привычными
            данными. Происходит реагирование именно на привычные данные. Текущие
            ощущения возбуждают ассоциативные связи с теми прежними ощущениями
            (данными), на которые и будет выработана реакция. </p>

   <p> <i> &gt; Означает ли это, что возможно один раз распознать
                картинку (момент времени t1), а в следующий момент времени (t1+1)
                уже можно анализировать её не заново, а только произошедшие в
                ней изменения? </i> </p>

   <p> Да, с одним уточнением. Не нужно распознавать "картинку" ни
            одного раза, поскольку поток сознания непрерывен. </p>

   <p> <i> &gt; Чисто технически в результате сравнения кадров получается
                множество точек, разлетающихся в разных направлениях, причем подмножества
                с одинаковыми векторами движения можно считать принадлежностью
                одного объекта? В результате получится расслоение на неподвижный
                фон + несколько объектов? </i> </p>

   <p> Зрительное восприятие очень не похоже на анализ массива точек.
            Техническое качество сетчатки заметно уступает обычной видеокамере.
            Природа придумала саккадирование не для того, чтобы следить за
            "объектами" или за "отличиями от предыдущего кадра", а для того,
            чтобы повысить детальность восприятия при использовании ограниченного
            разрешения сетчатки. </p>

   <p> В пределе, если бы на сетчатке глаза был только один "пиксель",
            который совершает очень быстрое сканирование видимой зоны, то
            зрительная информация в мозг будет проходить, в основном, не от
            этой единственной колбочки, а от мышц, управляющих саккадированием.
            Поэтому информация о видимой зоне содержится частично в динамике
            освещения колбочек и палочек, и частично в динамике движения глаза,
            но не в "фоне" или "объектах". И тем более, сами яркости и цвета
            "точек" не имеют важного значения и не воспринимаются. Воспринимается
            их динамика (темп изменения) в ассоциации с определённым усилием
            глазных мышц. </p>

   <p> <i> &gt; Как же теперь осуществить поиск и идентификацию объектов
                в памяти? </i> </p>

   <p> Если речь идёт о сознательной системе, то это невозможно.
            Но вы можете создать специальную память для хранения изображений,
            и тогда в ней можно найти, то, что туда положили. :) </p>

   <p> <i> &gt; Очевидно что для этого нужно формализовать их описание
                теми терминами которые уже имеются в памяти. </i> </p>

   <p> Формализация, придумывание и использование терминов входят
            в функции сознания и не отражаются в структуре мозга. Как слепая
            эволюция могла предусмотреть, о чём вы будете рассуждать? </p>

   <p> <i> &gt; я сижу перед висящим на стене ковром и пытаюсь придумать
                множество терминов </i> </p>

   <p> В вашей "памяти" ковёр - один из прочих идеальных образов.
            Он не представлен никакими распознаваемыми признаками в нейронах,
            обеспечивающих работу вашего сознания. </p>

   <p> &gt; &gt; детальность непосредственно воспринимаемого в данный
            момент потока информации не имеет критического значения для выбора
            поведения. </p>

   <p> <i> &gt; т.е. достаточно иметь/оценить только критические
                (max&amp;min) параметры? </i> </p>

   <p> Не нужно их оценивать. </p>

   <p> Если бы речь шла о станке или о шаговом экскаваторе, то его
            система управления должна оценить показания всех датчиков по определённой
            программе. Что важно, а что не важно - заранее было решено разработчиком. </p>

   <p> Если система обладает сознанием, то она не обязана, но может,
            если захочет, оценить критические или другие "параметры". Важно,
            что это не задача разработчика, а задача самой этой системы, обладающей
            заинтересованным отношением к миру. </p>

   <p> Поэтому разработка искусственного сознания в некотором смысле
            проще, чем разработка системы, которая делает всё точно, как задумал
            разработчик. </p>

   <p> &gt; &gt; Чем больше бабочка знает, тем больше она видит. </p>

   <p> Я не писал программу, которая бы определяла, как бабочка должна
            поступать в зависимости от того, что она видит. Это не моё, а
            её дело. </p>

   <p id="BM6">
    <b> Re: взгляд </b> <br> 24 июня 1999 г. 11:54 fido7.ru.ai </p>

   <p> Iskhakov Alex пишет </p>

   <p> <i> &gt; В отличие от компьютера человек все видит не как
                изменение цветов точек, а как их перемещение. Как реализовать
                это? </i> </p>

   <p> Это очень правильный вопрос. Хотя, я бы уточнил: в отличие
            от человека, компьютер вообще ничего не видит. Наверно, вы имели
            в виду какое-то устройство, вроде видеокамеры. Но и она ничего
            не видит в том смысле, как видят животные. Она только сохраняет
            или преобразует изображение в удобную для человека форму. </p>

   <p> Эволюционно, зрение развилось, как дополнительное средство
            выживания. Поэтому оно всегда субъективно и тенденциозно. Животное
            видит то, что для него важно и (или) интересно, конечно, в пределах
            физических возможностей зрения. Ничего подобного нет у видеокамеры.
            Например, я не замечаю, что пора красить пол на кухне. Но если
            посмотреть на него "глазами гостя", то это просто ужасно. :) </p>

   <p> Технически глаз тоже очень отличается от видеокамеры или фотоаппарата.
            Он скорее похож на сканирующий локатор. Поэтому традиционное распознавание
            изображения на "битмапе" не имеет ничего общего с нейробиологическим
            механизмом "узнавания". Сравните хотя бы число фоточувствительных
            элементов 100 000 000 и число волокон глазного нерва 1000 000
            у человека. </p>

   <p> Самая большая плотность колбочек и палочек на сетчатке имеется
            в области "глазной ямки" размером несколько миллиметров. Здесь
            расположено примерно 300x300 чувствительных элементов на 1 кв.
            мм. Это меньше, чем у обычных дисплеев. Но именно эта область
            сетчатки обеспечивает максимально резкое зрение на гораздо большей
            угловой площади, так как глаз совершает быстрые колебания (саккадирование)
            с углом около 10 градусов. </p>

   <p> Вот самые заметные отличия субъективного зрения от механического
            фиксирования изображения </p>

   <p> 1) Мы не видим "слепое пятно", но если бы на фотографии появилось
            "слепое пятно" площадью в 30% изображения, то оно воспринималось
            бы как явный дефект "зрения". </p>

   <p> 2) Глаз постоянно и очень быстро движется, так что перемещение
            головы при ходьбе или беге - это медленные движения по сравнению
            с собственным движением глазного яблока. Когда мы бежим нам всё
            же кажется, что здания и деревья вокруг нас остаются неподвижными.
            А попробуйте снимать эти здания быстро трясущейся видеокамерой! </p>

   <p> 3) Закройте глаза, и некоторое время вы будете помнить расположение
            предметов в общих чертах. А что будет помнить видеокамера, если
            закрыть объектив? </p>

   <p> Алгоритмически, животные видят не то, что есть, а то, "что
            должно быть". Объективные данные не воспринимаются непосредственно
            и изолированно от предшествующего опыта, а постоянно встраиваются
            в картину того, что должно быть, которая поддерживается нервной
            системой: мозгом, сетчаткой глаза, нервами глазных мышц с участием
            органов координации движения. </p>

   <p> Поэтому систему зрения, слуха или любого другого "заинтересованного"
            восприятия окружающего мира нужно строить не как систему анализа
            поступившего "массива данных", а как систему ассоциативного встраивания
            этих данных на лету в постоянно воспринимаемую целостную картину
            мира. </p>

   <p> Алгоритм, обеспечивающий сознание моей бабочки, устроен так,
            что бабочка воспринимает не текущий опыт, а прошлый опыт, похожий
            на текущий. Это получается статистически, потому что экземпляров
            прошлого опыта много, а текущий - всегда один. Кроме того, о прошлом
            опыте уже известно, к чему он может привести. Он известен вместе
            со своим будущим. И поэтому бабочка может заинтересованно оценить
            разные варианты своих действий. По мере накопления опыта, он переходит
            в разряд прошлого, освоенного опыта с известным будущим. Поэтому
            в прошлом опыте содержится объективная информация о действительных
            уже встретившихся закономерностях окружающего мира. В такой схеме
            важно, что детальность непосредственно воспринимаемого в данный
            момент потока информации не имеет критического значения для выбора
            поведения. Эта детальность не обязана быть предоставлена сейчас
            и во всей полноте. Она может накапливаться со временем. Чем больше
            бабочка знает, тем больше она видит. </p>

   <p id="BM4">
    <b> Re: Вера и ИИ
     <br> </b> 11 марта 1999 г. 14:04 relcom.sci.philosophy </p>

   <p> Evgenij Barsukov &lt; evgen@camd1.kkpcr.re.kr &gt; пишет </p>

   <p> &gt; &gt; "вера" в успешность одной из аксиом - это ваша вера,
            а не субъективная вера ИИ. </p>

   <p> Мы часто используем слова, обозначающие субъективное, идеальное
            восприятие, в применении к техническим системам: Word запомнил
            этот макрос; "Настоящее удовольствие" увеличилось на 1, а "псевдоудовольствие"
            уменьшилось. </p>

   <p> Для того, чтобы избежать такой путаницы в философии, нейробиологии
            и в ИИ используют понятия первой и третьей персоны. </p>

   <p> "Первая персона" воспринимает свой опыт в виде потока ощущений
            или потока сознания. Я как "первая персона" чувствую боль или
            удовольствие. Это прямое восприятие абсолютно не связано с тем,
            догадываюсь ли я о том, что у меня есть нервная система, и прокручиваются
            ли в ней какие-то гипотезы, теоремы или "псевдоудовольствия". </p>

   <p> Поскольку я знаю из опыта, что все люди во многом похожи на
            меня, то я догадываюсь (или даже не сомневаюсь), что и они испытывают
            боль и удовольствие. Но их боль абсолютно не доступна моим ощущениям.
            Я могу только "сочувствовать" им, но не чувствовать эту боль. </p>

   <p> Другой сознательный объект (третья персона) с точки зрения
            первой персоны выражает своё сознание через поведение. Я могу
            ему сочувствовать только в той мере, в какой я понимаю его поведение.
            В частности, я не понимаю, что испытывает осьминог. А специалист
            по осьминогам уже может это понимать. Но не чувствовать те же
            чувства, что и осьминог. </p>

   <p> Когда компьютер "запоминает" файл, то он не испытывает никакого
            особого чувства "необходимости" запоминания, а когда он "вспоминает"
            этот файл, то не испытывает никаких особых субъективных усилий
            и не осознаёт, что он что-то вспомнил. Это чисто механическая
            работа, как у хороших часов. Все части правильно пригнаны и при
            нажатии на определённые рычажки они выполняют задуманные конструктором
            действия. Если иногда и происходят непредусмотренные действия,
            то не потому, что компьютер проявляет свою волю, а потому, что
            конструктор, изготовитель компьютера, программист и пользователь
            - люди, и им свойственно ошибаться. </p>

   <p> Поэтому, как бы вы не назвали переменную в программе "настоящее
            удовольствие", "псевдоудовольствие" или "истинное наслаждение",
            это ничего не говорит о возможном субъективном восприятии создаваемого
            искусственного разумного существа. Если, о чудо, оно действительно
            что-то испытывает, то для того чтобы это понять невозможно использовать
            названия переменных. Нужны независимые испытания его поведения,
            такие же, как наблюдения за повадками осьминогов. </p>

   <p> <i> &gt; вы ведь представляете своей программе набор возможных
                действий. Например "влево, вправо, вверх, вниз". Вот их-то и можно
                перебирать. Как случайно, таки и систематически </i> </p>

   <p> Набор действий зависит от взаимных возможностей органов бабочки
            и внешнего мира. При получении команды "42" орган движения интерпретирует
            её как "2", потому что он понимает только команды 1,2,3,4. "2"
            означает движение вправо. Этот орган "прилагает усилие" вправо.
            И если внешний мир позволяет, то бабочка перемещается вправо или
            тормозит, если она в это время двигалась влево. Само перемещение
            происходит средствами внешнего мира (законов природы) и не входит
            в компетенцию мозга или органов бабочки. На следующем ходу мозг
            получает от органа движения результат исполнения команды - число
            "2". Таким образом орган движения является одновременно и эффектором
            и сенсором. Мозг не знает, что диапазон команд ограничен числами
            от 1 до 4, поэтому вопрос о переборе вариантов естественным образом
            снимается. :) </p>

   <p> <i> &gt; В момент каждого хода у бабочки есть набор показаний
                всех "органов" к-ми вы её наделили. Установщик весов использует
                все эти показания для установки веса на определенное действие. </i> </p>

   <p> Ещё раз извиняюсь, что я до сих пор не не поместил на веб-страничку
            описание своего алгоритма. Я давно уже пытаюсь его подготовить,
            но оказывается, что приходится разводить большую теорию, чтобы
            оправдать каждую процедуру. :) </p>

   <p> У меня нет весов для действий, и бабочка не использует "показания
            всех органов" на данном ходу. Она использует динамику этих показаний,
            то есть некоторую историю. Количество вариантов историй так велико,
            что даже для очень малого числа органов немыслимо перебирать эти
            варианты и присваивать им веса. Одна из бабочек (нет на сайте)
            движется вперёд без остановки, а орган движения только поворачивает
            её влево или вправо относительно направления движения. Такое движение
            очень инерционно. Бабочка попадёт на цветок, если она движется
            к нему в правильном направлении даже если последние несколько
            ходов она сделает неправильно. И не попадёт на цветок, если она
            быстро летит мимо него, даже если в последний момент она начнёт
            поворачивать в нужную сторону. Этот пример лучше того, что на
            вебе, так как использование довольно длинной истории в нём критически
            важно. </p>

   <p> <i> &gt; В вашей задаче бабочка видит только направление на
                цветок. Человек вошедший в ваш "МУД" будет видеть следующее:
     <br> &gt; слева: ничего
     <br> &gt; справа: ничего
     <br> &gt; сверху:цветок
     <br> &gt; снизу:ничего </i> </p>

   <p> Понятия "лево", "право" или алгоритм разбора таких вещей у
            бабочки отсутствуют. Бабочка не видит направления на цветок. Её
            орган зрения поставляет мозгу одно из чисел от 1 до 4. Мозг не
            знает, что невозможны другие числа, и что эти числа означают.
            Он увидит: "2". </p>

   <p> <i> &gt; Что сделает человек? Примет гипотезу что "что-то"
                это лучше чем "ничего" </i> </p>

   <p> Мозг "видит" такую последовательность чисел: 2222211222211222333331222222.
            Какая гипотеза отсюда может следовать? </p>

   <p id="BM8">
    <b> Re: Вера и ИИ
     <br> </b> 10 марта 1999 г. 22:44 relcom.sci.philosophy </p>

   <p> Evgenij Barsukov &lt; evgen@camd1.kkpcr.re.kr &gt; пишет </p>

   <p> <i> &gt; акт обучения будет происходить только на 100-м ходу
                (а скорее намного дальше т.к. до обучения движение происходит
                случайно). </i> </p>

   <p> Не "акт обучения", а получение положительной оценки. Действительно,
            бабочка начинает замечать закономерную связь между своим поведением
            и удовольствием не раньше, чем после нескольких попаданий на цветок. </p>

   <p> <i> &gt; В случае метода (СНД) случайного начального допущения
                (например орган чувств говорит "сделан ход вправо", орган удовольствия
                дает +1 </i> </p>

   <p> Я проверял, что внутренняя симуляция удовольствия обычно приводит
            к зацикливаниям вроде эпилепсии. Максимальная скорость обучения
            всё же достигается при объективной, внешней оценке, даже если
            она даётся один раз за сто ходов. </p>

   <p> <i> &gt; и случайная выборка останется оптимальным методом
                (наряду с систематическим перебором к-й будет лучше в non-biased
                systems). </i> </p>

   <p> Перебором чего? Для "систематического перебора" надо знать
            особенности решаемой задачи. Это может знать только сама бабочка,
            как сознательное существо, но не её мозг, который изолирован от
            внешнего мира. Бабочка может устроить перебор понятных ей вариантов
            и может принять на веру какую-то гипотезу, но этот конкретный
            сознательный процесс находится вне компетенции абстрактного творческого
            алгоритма. </p>

   <p> <i> &gt; "ход туда где вижу что-то=хорошо" (если у бабочки
                есть зрение) приведет к очень быстрому решению. </i> </p>

   <p> Видят глазами, а ходят ногами. Поэтому само понятие "туда,
            где вижу" становится доступно только после обучения, во время
            которого происходит ассоциативная координация действия разных
            органов. </p>

   <p> Более простая гипотеза "цветок увеличивается - это хорошо"
            быстрее станет доступна бабочке, так как она относится только
            к зрению. Хотя она ничего не говорит о том, как правильно двигаться,
            но она правильно оценивает успешность каждого (а не каждого сотого)
            движения. Правда, для возникновения такой гипотезы бабочка должна
            обладать "чувством увеличения цветка". У моей бабочки такого чувства
            нет, чтоб жизнь малиной не казалась. </p>

   <p id="BM3">
    <b> Re: Математика &amp; Физика
     <br> </b> 28 октября 1998 г. 22:43 fido7.su.science </p>

   <p> Roman Sandakov пишет... </p>

   <p> <i> &gt; откуда должно взяться веселье у ИИ? </i> </p>

   <p> Раз уж механизмы сознания у искусственного и натурального
            разума похожи, или даже одни и те же, то между их проявлениями
            должно быть много общего. Типичные болезни сознания типа шизофрении
            и эпилепсии, лёгкие расстройства типа зацикливания на одной идее,
            и эмоции типа радости, страха и юмора - всё это я наблюдаю и в
            своей теоретической модели сознания. А кое-что и в проведённых
            тестах алгоритма. Так что, методы приведения кибер-разума в порядок
            и в хорошее расположение духа, наверно, можно будет применять
            и к людям. </p>

   <p> Вот, например, как сознание порождает радость и юмор. Автоматический
            внутренний механизм сознания постоянно прогнозирует ближайшее
            будущее. И постоянно ожидает, что прогноз не оправдается, потому
            что так оно обычно и происходит. На случай, если будущее окажется
            хуже, чем прогноз, создаётся излишний запас средств мобилизации
            (адреналин, жиры и т.п.) Если же вдруг реальность оказалась лучше,
            чем прогноз, то возникает избыток неизрасходованных средств самозащиты,
            некоторые из которых не могут храниться, и должны быть немедленно
            израсходованы. Поэтому возникает неопасная для окружающих и не
            вызванная агрессивными намерениями высокая двигательная активность.
            Это и есть радость. </p>

   <p> Если неожиданный благоприятный результат получен чисто интеллектуальным
            путём (например, осуществление догадки), то такую радость мы воспринимаем,
            как чувство юмора. Для искусственного интеллекта это более характерно,
            чем "адреналиновая" радость, потому что у него не развит механизм
            самосохранения, а интеллект есть. </p>

   <p> Это грубая схема. Есть ещё разновидности радости и юмора вроде
            "радости ожидания". Это компетенция психологии. </p>

   <p id="BM10">
    <b> Re: Изменение </b> <br> 24 июля 1998 г. 22:36 fido7.su.philosophy </p>

   <p> Roman Korobov &lt; roman@ufps.magadan.su &gt; пишет </p>

   <p> <i> &gt; как рождается абстракция ? </i> </p>

   <p> Абстракция - это высший уровень обобщения. Уровень обобщения
            увеличивается постепенно по мере накопления опыта об экземплярах
            того, что обобщается. </p>

   <p> Простейший уровень обобщения - узнавание. При узнавании происходит
            хотя бы небольшое абстрагирование, так как в природе ничего не
            повторяется точно. </p>

   <p> Механизм узнавания основан на ассоциативном сравнении текущей
            ситуации с прежними. Такое сравнение возможно потому, что "прошлый
            опыт" запоминается в такой же форме, как и "текущий опыт". Например,
            может запоминаться изменение во времени концентрации каких-то
            ферментов. Подобный механизм запоминания динамики "внутреннего
            состояния" есть у всех живых организмов с нервной системой. Поэтому
            они все способны к абстрагированию в той или иной степени. </p>

   <p id="BM9">
    <b> Re: Тест на способность обучаться </b> <br> 31 мая 1998 г. 2:14 fido7.ru.ai </p>

   <p> Andrew Filinsky пишет </p>

   <p> <i> &gt; была ли реализована модель, которая прошла тест на
                способность обучаться? </i> </p>

   <p> . .. в двух последних заметках "Тест на способность обучаться"
            и "Зарождение смысла" я процитировал куски из своей небольшой
            веб статьи о механизме сознания. </p>

   <p> У меня на сайте есть демонстрация работы этого механизма,
            воплощённого в несложный алгоритм. Сейчас я навожу на него некоторый
            объектный лоск. Возможно, в этом году я сделаю более убедительный
            пример. Тогда и подготовлю описание алгоритма. Это описание не
            удаётся сделать коротким, так как алгоритм не содержит нейронов
            и даже "мозга". И я пока не нашёл безболезненную форму, как это
            донести до публики. :) </p>

   <p> Моя кибер бабочка проходит тест на способность к обучению.
            Но для проведения опытов с этой бабочкой нужно иметь изрядное
            терпение, как и при опытах с примитивными животными. </p>

   <p> Во-первых, сразу после запуска программы эта бабочка ничего
            не умеет и ничего не понимает. Со временем она самостоятельно
            приучается лететь в сторону цветка. Хотя никаких "физических"
            воздействий (вроде запаха) со стороны цветка нет. Она летит к
            нему только потому, что знает, что получит удовольствие, когда
            коснётся цветка. Это чисто интеллектуальное стремление. </p>

   <p> Если вам недостаточно, того, что она научилась ориентироваться
            в пространстве, попробуйте её переучить. Например, это можно сделать
            так. Не давайте ей достигнуть цветка, и в последний момент, перед
            тем как она его коснётся, переносите цветок в какой-нибудь угол
            окна. Например, в правый нижний. И держите его там, пока бабочка
            до него не долетит. После этого поместите цветок куда-нибудь в
            другое место. И опять в последний момент перенесите в правый нижний
            угол. А можно просто долго держать цветок в этом углу. Через некоторое
            время (будьте готовы, что это 10-20 минут, а то и больше), она
            вообще перестанет вылетать из угла, даже если вы уберёте из него
            цветок. Вот вам и новое поведение. :) </p>

   <p> <i> &gt; Каковы были связи между нейронами (многослойная /
                однородная сеть)? </i> </p>

   <p> Сенсорный поток бабочки составляет всего 5 бит: 2 бита зрение,
            2 бита движение и 1 бит касание цветка. Я тестировал свой алгоритм
            на способность к прогнозу и к самообучению ещё до появления бабочки
            на тестах из 32 бит. </p>

   <p> Нейронные сети пропускают гораздо больше информации, и я думаю,
            что практически любая обучаемая нейронная сеть пройдёт этот тест.
            Но у бабочки нет нейронов. Её органы имеют собственную память
            и общаются между собой чисто ассоциативно, так как непосредственная
            информация понятная одному органу не доступна другому. Например,
            зрение не приспособлено "перемещать" бабочку. </p>

   <p> Но сам орган зрения может содержать нейронную сеть для повышения
            эффективности узнавания. </p>

   <p id="BM2">
    <b> Re: (4) Механизм предвидения
     <br> </b> 22 мая 1998 г. 17:46 relcom.sci.philosophy </p>

   <p> Konstantin E.Yushtin пишет </p>

   <p> <i> &gt; если существо засунуть в абсолютно новые условия,
                будет ли оно предвидеть ? </i> </p>

   <p> Да! Я не точно сказал о бабочке, что попав в новый для неё
            мир, она ничего не узнаёт. На самом деле механизм ассоциативного
            узнавания работает неостановимо, как и сознание в целом. Поэтому
            субъективное "узнавание" есть всегда. Но в абсолютно новых условиях
            это узнавание всегда ошибочно. Также и предвидение будет продолжать
            работать в новом мире, но поначалу будет "предвидеть", то, чего
            на самом деле не произойдёт. </p>

   <p> По мере накопления нового опыта и узнавание и предвидение
            становятся всё более точными. </p>

   <p id="BM1">
    <b> Re: Спасибо, alys!
     <br> </b> 16 ноября 1997 г. 00:30 relcom.sci.philosophy </p>

   <p> Представьте себе, что мозг - это живое существо, которое живёт
            внутри головы. Назовём его Мозг. Он соединён с внешним миром (то
            есть, с органами человеческого тела) через нервные волокна. </p>

   <p> Мозг питается от кровеносной системы и получает информацию
            от нервной системы. Обе находятся внутри человеческого тела. Также
            и человек питает своё тело от внешнего мира и получает информацию
            через свои 5 чувств тоже от внешнего мира. </p>

   <p> Человек имеет сознание. Одна из вещей, которые являются причиной
            нашего сознания, это мозг. Животные имеют менее мощный мозг. Может
            быть, они не имеют сознания. Это к теме не относится. </p>

   <p> Теперь вопрос. Мозг имеет сознание? Нет сомнений, что "мозговая
            мощность" мозга не меньше, чем у человека. Более того, входными
            сигналами для мозга являются нервные сигналы. Они же и есть родной
            язык меж-нейронных контактов. Поэтому Мозг получает более "непосредственную"
            информацию о своём внешнем мире, чем человек. </p>

   <p> Даже если Мозг думает и осознаёт себя, его окружающая среда
            так отличается от нашей, что понимание и контакт между человеком
            и его мозгом невозможны. </p>

   <p> Часть "сознательных мыслей" Мозга, если они существут, влияет
            на наше подсознание. </p>

   <p> <a href="../post/email.html" rel="author" title="email и копирайт">
     Евгений Корниенко </a> </p>
  </main>

  <div id="menu">
  </div>

  <footer>
  </footer>

  <noscript>
   <div>
    
   </div> </noscript>
 </body>
</html>