<!DOCTYPE html>
<html lang="ru">
 <head>
  <title> Рабочий дневник AI-1996 </title>
  <meta content="Не только учитель воздействует на ученика с определенной целью, но и наоборот, ученик на учителя. Целью ученика является получение хорошей оценки." name="description">
  <meta content="вход, выход, данные, заинтересованность, информация, нейрон, обучение, перекодировка, поведение, подсознание, сигнал, система, среда, таблица, " name="keywords">
  <meta content="Евгений Корниенко" name="author">
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1" name="viewport">
  <link href="https://cord70.github.io/cyber/study/AI-1996.html" rel="canonical">
  <link href="https://cord70.github.io/cyber/favicon.svg" rel="icon" sizes="any" type="image/svg+xml">
  <link href="../images/main.css" rel="stylesheet">
  <script defer="" src="navStudy.js"> </script>
  <script defer="" src="../images/ansimeta.js"> </script>
 </head>
 <body>

  <header>
  </header>

  <main>
   <p class="headquote">
    При решении творческой задачи, то есть такой,
            которую неизвестно как решать, творец делает разные случайные
            или осмысленные попытки решения в окрестности того, что ему известно.
    <i> Благодаря его заинтересованности он более чем другие </i> , способен оценить, что какая-то из попыток приближает его к решению
            задачи. После этого происходит исследование вновь открывшихся
            возможностей. </p>

   <h2> Рабочий дневник 1996 </h2>

   <p> Эти записи не предназначались для публичного чтения. Они содержат
            кучу ошибочных предположений. Многие заявления являются или кажутся
            логически не связанными, необоснованными или просто противоречащими
            друг другу. Некоторые рассуждения относятся к алгоритму и ссылаются
            на имена переменных, которых давно уже нет в программе, так как
            она постоянно изменяется. </p>

   <p> Здесь вы видите булыжник, от которого ещё предстоит отсечь
            всё лишнее, чтобы стало ясно "что такое разум и как его изготовить".
            При чтении этих записок, не упускайте из виду, что мои взгляды
            со временем меняются. </p>

   <p> Надеюсь, что мои сырые, но довольно конструктивные размышления
            внесут вклад в развитие ваших собственных идей и ваших алгоритмов
            универсального ассоциативного обучения. </p>

   <h3 id="BM1">
    Разработка самообучающейся системы </h3>

   <h3> 25.11.96 </h3>

   <p> <b> Среда </b> , (учитель, мир): Активный источник информации
            . </p>

   <p> <b> Цель </b> : Потребность в получении информации, обусловленная
            внутренними причинами. </p>

   <p> <b> Ученик </b> : Система, воздействующая на
    <b> среду </b> с определенной
    <b> целью </b> или без цели, и воспринимающая реакцию
            среды. Далее станет ясно, что ученик способен самообучаться. </p>

   <p> Не только учитель воздействует на ученика с определенной целью,
            но и наоборот, ученик на учителя. Целью ученика является получение
            хорошей оценки. Если же обучение происходит без заинтересованности
            ученика, то это не ученик, а база данных, например, словарь, или
            шахматная программа. </p>

   <p> Но техническая система должна допускать быстрое обучение без
            заинтересованности, если это теоретически возможно. </p>

   <p> На начальном этапе, пока интеллект ещё не развит или задача
            слишком новая, обучение может происходить без заинтересованности.
            Например, крысу приучают нажимать на педаль после звонка. Разве
            она могла быть в этом заранее заинтересована? Улитка или бабочка
            ищет по запаху другую улитку (бабочку). Не найдёт, у неё не будет
            потомства. Учителем оказывается естественный отбор, а полезный
            "результат обучения" запоминается в ДНК. </p>

   <p> Следовательно, некоторые основные
    <b> разумные </b> (intelligent,
            то есть, исходящие от мозга) инстинкты зашиты в мозг и для них
            обучение не требуется. Как это получается? Мозг, как и другой
            орган тела, развивается даже и без обучения. Если его внутренние
            структуры содержат уже жизненно необходимые знания, то такая особь
            выживет, даст потомство. (Зашитая в ДНК схема правильной внутренней
            структуры мозга способствует выживанию этой ДНК.) Кроме того,
            мозг способен к самообучению. Если эта способность достаточно
            развита, то особь лучше будет ориентироваться и адаптироваться
            в мире и с большей вероятностью выживет. Уровень способностей
            к самообучению может быть разным, что тоже определяется генетически.
            Чем лучше, те больше шансов продолжения рода. В итоге, число умных
            особей увеличивается. </p>

   <p> Привыкание к неожиданно изменяющемуся внешнему миру, конечно,
            происходит без заинтересованности, но не бессознательно. При привыкании
            приходится приучаться к новому, полезному для данного существа
            поведению. Привыкание, адаптация или самообучение менее эффективно,
            чем обучение учителем. Самообучение без постоянного стимулирования
            (без заинтересованности в самом процессе учёбы) похоже на естественный
            отбор, а обучение с учителем - на искусственный. Из некоторого
            количества реакций на заданные условия учитель выбирает и поощряет
            только правильные реакции, а также показывает правильное поведение
            или принуждает к правильному поведению. </p>

   <p> Также объясняется и творчество. При решении творческой задачи,
            то есть такой, которую неизвестно как решать, творец делает разные
            случайные или осмысленные попытки решения в окрестности того,
            что ему известно.
    <i> Благодаря его заинтересованности он более
                чем другие </i> , способен оценить, что какая-то из попыток приближает
            его к решению задачи. После этого происходит исследование вновь
            открывшихся возможностей. И так далее. Если творец ошибся в самооценке,
            то он может зайти в тупик и не решить задачу. Не каждому дано.
            Или не каждому везёт. </p>

   <p> В природе хорошей оценкой может быть получение пищи или избежание
            вреда. В принципе, любое воздействие ученика на среду можно трактовать,
            как вопрос. А также, любое воздействие обучающейся системы на
            среду можно трактовать, как вопрос. Такой системой может быть
            мозг, а объективной средой для него - внутренние органы тела. </p>

   <p> <i> Среда не может не ответить. Положение Среды и ученика
                в некотором смысле равноправны. Любое действие Среды можно трактовать
                как вопрос (или приказ) ученику. И ученик обязан отвечать. Игры,
                в которых можно думать сколько угодно, - это игры, а не живое
                неостановимое сознание. </i> </p>

   <p> Целью учителя является скорейшее приучение ученика к определенному
            поведению путем сообщения ему нужной информации и выставления
            оценок за его поведение. Учитель является фильтром между средой
            и учеником. </p>

   <p> <b> Семантика. </b> Пусть имеется ученик с входом для оценок
            и выходом для информации. Ученик способен выдавать на выход нули
            0 или единицы 1. Надо приучить его к выдаче только нулей. Очевидно,
            что поведение учителя должно состоять в том, чтобы ставить хорошую
            оценку за каждый 0. Также можно его приучить выдавать только Yes.
    <br> * Пусть ученик первоначально способен выдавать разные слова.
            Но выдаст ли он когда-либо слово Yes?
    <br> * Почему ученик способен выдавать слова? </p>

   <p> <b> Объектная структурность </b> .
    <i> Все алгоритмы блоков
                системы должны быть одинаковыми. То есть, они действуют одинаково
                над разными наборами данных. Количество и структура вложенности
                блоков заранее не определено.
     <br> * Либо они имеются в избытке.
     <br> * Либо строятся по мере необходимости.
     <br> * Либо над разными типами данных рекурсивно действует один
                блок. </i> </p>

   <p> <b> Семантика. </b> Как определить, что эта буква не может
            стоять после этой? Это слово не может быть после этого? Как это
            сделать, не имея словаря всех слов и всех фраз? Для этого ученик
            должен обладать способностью к обобщению. Что это значит и как
            это формализовать? </p>

   <h4> Обобщение (def): </h4>

   <p> <b> a. </b> Выделение некоторого логически нового типичного
            объекта из потока данных так, что этот объект может быть описан
            по характерным для него свойствам. </p>

   <blockquote>
    <p> <b> В терминах ассоциаций, это установление новой устойчивой
                    связи между известными старыми объектами. </b> </p>

    <p> <i> Что такое логически новый объект? Как это формализовать,
                    или определить более конструктивно? Можно считать логически новым
                    объектом такой объект, которому приходится присваивать имя, для
                    удобства работы с ним. То есть сама новизна субъективна. А присвоение
                    имени технически может произойти для упрощения ссылок на этот
                    объект, которые иначе были бы слишком длинными. </i> </p>
   </blockquote>

   <p> <b> b. </b> Узнавание в новом предмете предмета, отнесённого
            ранее к определённому классу. </p>

   <blockquote>
    <p> <i> Алгоритмически, это просто узнавание. Степень новизны
                    предмета субъективна. </i> </p>
   </blockquote>

   <p> <b> c. </b> Применение правил, выработанных ранее в одной
            предметной области, к другой предметной области. </p>

   <blockquote>
    <p> <i> Что такое предметная область с точки зрения мозга? Ведь
                    для мозга все информационные каналы имеют одинаковую природу. </i> </p>
   </blockquote>

   <p> <b> Обобщение </b> - это абстрактный алгоритм, действующий
            над данными любой природы. То есть, благодаря обобщению становится
            возможным видеть общее в разных явлениях. Поэтому можно применять
            одни и те же приемы работы с разными объектами. </p>

   <p> Может быть, внутренний стимул ученика (стимул для мозга) это
            высвобождение внутренних ресурсов (памяти, разнообразия, скорости
            и др.) благодаря обобщению. Возможно, стимулом (существа, ученика)
            является способность
    <b> предвидеть </b> получение хорошей оценки
            за определенное поведение. Стимулом является сама хорошая оценка.
            А способность предвидеть создаёт мотив, цель, целенаправленные
            действия для получения хорошей оценки. Аналогично, страх - предвидение
            худшего. </p>

   <h3 id="BM2">
    26.11.96 Нейронная сеть </h3>

   <p> Пусть обучающаяся структура состоит из однородной сети "нейронов"
            + датчики-преобразователи на входе и выходе. Нейрон имеет несколько
            входов и выходов. Он представляет собой структуру, имеющую индивидуальное
            поведение, которое заключается в том, что при определенном входном
            сигнале он выдает определенный выходной сигнал в соответствии
            с внутренней таблицей перекодировки. Пусть нейрон имеет до 8 входов
            для бит и до 8 выходов для бит. Тогда таблица имеет объем 256
            байт. Это "полная таблица перекодировки". Однако здесь
            нет динамики! </p>

   <p> Со временем информация в таблице забывается (портится?), а
            после получения положительной оценки она некоторое время остается
            стабильной. То есть, положительная оценка предназначена для поддержания
            жизни всех накопленных данных (методов обработки данных). Входы
            и выходы могут быть аналоговыми или информационно насыщенными
            (например, нейрон может принимать и выдавать слова из словаря).
            Такой нейрон обучаем. </p>

   <p> <b> Забывание </b> не так важно, как может показаться. Это
            свойство имеется у биологического нейрона, но мы не обязаны его
            воспроизводить. Если забывается то, что не используется, то это
            конструктивно ни на что не влияет, то есть, не влияет на функционирование
            системы, как если бы забывания совсем не было. Таблица может быть
            не полной (не полностью обученной). </p>

   <p> <b> Положительная оценка </b> должна относиться не только
            к текущему мгновенному состоянию ученика, но и к ряду его предыдущих
            действий. Так ученик сможет понять связь между вопросом и ответом,
            выдаваемым через некоторое время (и сможет стремиться через ряд
            действий, то есть, имея цель и план, к хорошей оценке). Выходит,
            что нейрон должен помнить свои предыдущие действия. </p>

   <p> Физический (биологический) нейрон - это клетка с некоторой
            изменяющейся внутренней структурой. Некоторая положительная оценка
            (фермент) замораживает структуру, но со временем она опять изменяется,
            если нет подпитки стимулирующим ферментом. Поэтому оценки должны
            быть достаточно частыми. </p>

   <p> Обучаемая структура состоит из большого количества нейронов.
            Входы подключены к выходам и к датчикам сигналов среды. Каждый
            выход может быть подключен к нескольким входам. Некоторые выходы
            подключены к датчику (преобразователю) для воздействия на среду.
            Некоторые входы и выходы могут не использоваться. </p>

   <p> <b> Пример 1. </b> Построим однородную замкнутую нейронную
            сеть. Удалим один нейрон. Его место займет среда. При этом получится:
    <br> <i> Если у нейрона входов больше, чем выходов, то у сети
                (и у среды) - наоборот. </i> </p>

   <p class="center">
    <img alt="Схема среды похожа на схему
      нейрона" height="186" src="images/96-01.gif" title="Среда может заменить 1 нейрон" width="323"> </p>

   <p> <b> Пример 2. </b> Подключим к произвольным точкам нейронной
            сети датчик выходного сигнала. Оборвем некоторое количество входов
            нейронов и подключим к ним датчик входного сигнала. </p>

   <h3 id="BM3">
    Технология обобщения. </h3>

   <p> Пусть таблицы перекодировки существуют как независимые объекты,
            а нейроны их используют (биологически это невозможно). Положительный
            стимул воздействует на таблицу, а не на нейрон. Пусть число таблиц
            ограничено, а нейронов - нет. Тогда, если какие-то нейроны вдруг
            обнаруживают, что их таблицы совпали, то они переходят к использованию
            одной общей таблицы, а освободившаяся таблица достается новому
            нейрону. Топология сети должна позволять добавление нейронов. </p>

   <p> Если таблицы большие (сотни байт), то точное, и даже разумно-приближённое
            совпадение невозможно. </p>

   <p> Физически и технически быстрый поиск близких таблиц можно
            выполнять путем сортировки. Медленный поиск можно выполнять путем
            случайного сравнения. Если не требовать точного совпадения, то
            становится возможной "догадка". При обнаружении одинаковых
            таблиц одна из них освобождается (и сбрасывается), а вторая получает
            стимулирующую оценку. Механизм сравнения таблиц и общий пул для
            таблиц являются внешними управляющими структурами относительно
            нейронной сети. Это нежелательно и, видимо, этого нет в природе.
            Но раз уж мы имеем только один процессор для опытов, то можно
            применить и 1 супервизор. </p>

   <p> Такая структура нейронов обучаема и способна к обобщениям.
            Её внутренняя жизнь (подсознание) заключается в поиске обобщений
            (и имеет стимул?) </p>

   <p> Среда вместе с датчиками входной и выходной информации воспринимается
            нейронной сетью как один (или несколько) из нейронов и тоже может
            участвовать в процессе поиска обобщений. Так, естественным путем,
            возникают вопросы к среде (любознательность). </p>

   <p> В общем, любое воздействие на среду можно считать вопросом.
            Ученик не уверен заранее в ответной реакции среды. Однако среда
            не имеет таблицы перекодировки. Такую таблицу можно строить в
            реальном времени по мере диалога со средой и сравнивать эту виртуальную
            таблицу с таблицами других нейронов. (Это опять внешняя функция). </p>

   <p> При этом обобщение не удается, но положительная оценка может
            быть получена за совпадение внутренней перекодировки с внешним
            диалогом. Виртуальная таблица среды имеет абсолютную истинность
            и не портится от времени, но постоянно изменяется в результате
            практики общения со средой.
    <i> Это утопия и внешнее заданное
                свойство </i> . Если "внешняя таблица" включает всю
            динамику внешнего мира, то есть все законы природы, то, в принципе,
            она тоже не изменяется, но она весьма велика. :) </p>

   <h3 id="BM4">
    27.11.96 Вопросы. </h3>

   <ol type="a">
    <li> Сколько входов и выходов оптимально? </li>
    <li> Какой тип данных оптимален? </li>
    <li> Какая степень общения со средой оптимальна?
     <i> Мощность
                    мозга должна соответствовать мощности датчиков, сообщающихся с
                    внешним миром. </i> </li>
    <li> Как построить оптимальный обучающий алгоритм? </li>
    <li> Какое значение имеет структура нейронной сети? </li>
    <li> Какая степень совпадения таблиц перекодировки достаточна
                для обобщения? </li>
    <li> Как разделить таблицу при обнаружении отсутствия общности? </li>
    <li> Можно ли установить, что вывод об общности был ошибочным? </li>
    <li> Как построить эффективный стимул? Важна ли количественная
                оценка? </li>
    <li> Какое подсознание кроме функции обобщения требуется? </li>
    <li> Нужно ли нейронам спать? Имеет ли смысл части сети отключиться
                от всех и заняться собственным обустройством?
     <i> Это в компетенции
                    супервизора. </i> </li>
    <li> Можно ли иметь общую таблицу для перекодировки и коммутации? </li>
    <li> Важно ли, чтобы нейроны работали параллельно или допустима
                последовательная обработка сигналов? </li>
   </ol>
   <p> /// Почитать о биологии клетки. </p>

   <h3 id="BM5">
    Обобщение (биологический алгоритм). </h3>

   <p> Пусть таблицы перекодировок встроены в нейроны и не могут
            быть общими. Пусть таблица может принимать не произвольные значения,
            а некоторые фиксированные. Тогда они порой будут становиться одинаковыми
            у разных нейронов и, ничего об этом не зная, нейроны будут действовать
            одинаково над разными объектами. Логически можно понять, что это
            и есть обобщение. А практически: одинаковая логика воспроизводится
            в большом количестве экземпляров. При этом сам мозг не обнаруживает
            наличия одинаковых таблиц и при возникновении таких таблиц не
            возникает никаких положительных оценок и стимулов. Просто общность
            нейронных таблиц соответствует общности реальных природных объектов,
            что может осознать только интеллект (intellect, intelligence).
            В чем тогда заключается подсознание (бессознательная, неосознавемая
            полезная работа нейронов)? </p>

   <p> Подсознание есть просто постоянное функционирование системы
            без определенной цели.
    <b> Только если система сможет предсказывать
                поведение среды, может возникнуть цель - получение стимула </b> . Основная цель биологического мозга: поддержание согласованной
            работы всех систем организма и, в конце концов, выживание и размножение.
            Это и есть
    <b> "адаптация к изменяющемуся миру". </b> </p>

   <p> Как возникает механизм предвидения? Никакие супервизоры и
            централизованные органы управления не желательны. Нужно выбирать
            не тот диалог, который ведёт к высокой немедленной оценке, а тот,
            который продолжается дольше всего с сохранением положительной
            оценки. Если система вырабатывает своё поведение, то это похоже
            на диалог. </p>

   <ol>
    <li> Существует ли логический механизм миграции обобщения по нейронной
                сети? </li>
    <li> Может ли вообще какая-либо логическая структура физически
                перемещаться по сети? </li>
    <li> Существует ли сплошная аналогия сети - обучаемый континуум? </li>
    <li> Существует ли обучаемый континуум диалогов? </li>
    <li> Можно ли установить аналогию между нейроном и элементом (но
                не узлом) конечно-элементного разбиения пространства? </li>
   </ol>
   <h3 id="BM6">
    3 декабря 1996. Ответы </h3>

   <h4> Сколько входов и выходов оптимально? </h4>

   <blockquote>
    <p> Отделим часть нейронной сети замкнутой поверхностью. Вместо
                всего, что окружено, вводим новый нейрон. Все входящие в контур
                выходы подключаем к входам этого нейрона, а все выходящие из контура
                входы прочих нейронов подключаем к выходам нового нейрона. Новая
                крупная сеть логически совпадает со старой мелкой сетью, если
                не принимать во внимание задержки в распространении сигналов.
                Может только она несколько мощнее, так как имеет потенциально
                более полную таблицу перекодировки. </p>
   </blockquote>

   <blockquote>
    <p> Итак, сколько входов и выходов все равно. Сколько удобно,
                столько и лучше. Вероятно несколько лучше большее количество входов
                и выходов. Вместе с тем, большой нейрон без внутренних задержек,
                в отличие от нескольких маленьких, не способен запомнить последовательность
                действий. Если все связи внутри контура поменять на "скрытые"
                входы и выходы или ввести внутреннюю линию задержки, или запоминать
                весь диалог, то запомнить последовательность действий можно. </p>
   </blockquote>

   <h4> Какой тип данных оптимален? </h4>

   <blockquote>
    <p> Непрерывные (аналоговые) данные логически эквивалентны большому
                количеству разрядов дискретных данных. Поэтому оптимален удобный
                тип данных. Однако обработка дискретных данных дискретной сетью
                более эффективна. Числовые и логические данные обрабатываются
                одинаково, если допустима только операция равенства, но сравнения
                "больше или равно" запрещены. Могут быть сравнения массивов
                логических данных с результатом "лучше, хуже". Можно
                сделать часть каналов символьными, а часть - аналоговыми. </p>
   </blockquote>

   <h4> Какая степень общения со средой оптимальна? </h4>

   <blockquote>
    <p> Чем больше, тем лучше. В крайнем случае, не вся информация
                будет использована. Например, лучше иметь информацию о расстоянии
                до объекта и о контакте с объектом, чем только о контакте. А вообще,
                у живого мозга примерно 1/1000 (?) внешних связей, остальные -
                внутренние. Оптимальная степень определяется воспринимающей системой.
                Надо, чтобы получаемые данные использовались в полной мере. А
                реакция должна обеспечивать решение жизненных задач системы. </p>
   </blockquote>

   <h4> Как построить оптимальный обучающий алгоритм? </h4>

   <blockquote>
    <p> Алгоритм должен быть оптимальным как по скорости обучения,
                так и по удобству наблюдения за обучением и за результатами. Для
                экспериментов удобно построить искусственный мир в виде понятного
                графического объекта. Нужно сделать так, чтобы этот мир подавал
                на входы сети существенную и видимую информацию о себе и явно
                реагировал, на активные действия обучающейся системы, то есть
                на сигналы, попадающие на выходы нейронной сети. </p>

    <p> Например, пусть мир представляет собой круг, в одной точке
                которого находится еда (стимул, положительная оценка). Обучаемая
                система может делать шаг влево или вправо вдоль окружности (выдавая
                0 или 1 на выход). Мир реагирует на это перемещением точки влево
                или вправо. При попадании в точку с едой мир выдает оценку, и
                сигнал (еду) на вход. </p>

    <p> При этом обучающаяся система может содержать 1 нейрон с 1
                выходом и 2 входами. 1 для еды и 1 для информации о своем перемещении. </p>

    <p> В литературе описаны два основных способа обучения: самообучение
                и обучение с учителем. Учитель может вести систему "за ручку"
                по правильному пути. При этом она не может научиться определять
                путь, но будет знать, какой путь правильный. Обучение включает
                2 части: Наблюдение и синтез поведения. </p>
   </blockquote>

   <h4> Какое значение имеет структура нейронной сети? </h4>

   <blockquote>
    <p> Похоже, что небольшое. Смотри вопрос о количестве входов и
                выходов. Чем больше нейроны, тем более сложную информацию они
                могут хранить. Чем больше нейронов, тем более продолжительную
                последовательность действий они могут хранить (?). Желательно,
                чтобы все входы и выходы использовались. Если 1 нейрон помнит
                бесконечно длинный (и широкий) диалог и способен к синтезу, то
                сеть не нужна. </p>
   </blockquote>

   <h4> Какая степень совпадения таблиц перекодировки достаточна
            для обобщения? </h4>

   <blockquote>
    <p> Для биологического алгоритма этот вопрос не имеет смысла.
                Для оптимизированного алгоритма лучше для начала требовать точного
                и достаточно устойчивого (продолжительного) совпадения. Чем меньше
                разрядность данных, тем больше совпадающих таблиц. </p>
   </blockquote>

   <h4> Как разделить таблицу при обнаружении отсутствия общности? </h4>

   <blockquote>
    <p> Нет такой необходимости. При появлении противоречий должны
                возникнуть уточняющие пути в нейронной сети. Для уточнения (проверки)
                общности можно иногда разделять таблицы. Они потом сами объединятся,
                если останутся общими. </p>
   </blockquote>

   <h4> Можно ли установить, что вывод об общности был ошибочным? </h4>

   <blockquote>
    <p> Это не нужно делать. Смотри вопрос о проверке общности. </p>
   </blockquote>

   <h4> Как построить эффективный стимул? </h4>

   <blockquote>
    <p> Кроме общей стимуляции всей сети можно ввести стимулы (положительные
                оценки) для участков сети (органов), принимающих от среды или
                передающих среде определенный тип информации. Например, при приеме
                "еды" положительную оценку (большую, чем другие) получают
                нейроны, подсоединенные к датчику еды и соседние с ними. </p>

    <p> Положительный стимул закрепляется и ассоциируется с некоторым
                сигналом, если этот стимул при обучении сопровождался таким сигналом.
                Например, стремление к получению положительной оценки может выразиться
                в создании условий для возникновения такого сигнала (еды). Возможно,
                надо ассоциировать положительную оценку с любой реакцией внешней
                среды. (Это неверно; среда всегда реагирует.) </p>

    <p> Ученик должен стимулировать среду. Чтобы с ним хотелось общаться.
                Практически,
     <i> среда не может не реагировать </i> . Поэтому
                надо стимулировать только определенные каналы связи, например,
                речевые. Стимул должен действовать на каждое звено иерархии: сеть,
                нейрон, память, ячейка памяти. </p>

    <p> <b> Количественная оценка важна </b> . Как иначе показать,
                что оценивается не просто наличие ответа, а качество ответа. Кроме
                того, количественная оценка создаёт больший материал для ассоциаций.
                Нейрон может ставить себе самооценку, если предсказал реакцию
                среды. Стимул может "делегироваться" от нейрона, который
                "ставит задачу", к нейрону, который решает задачу. </p>
   </blockquote>

   <h4> Какое подсознание кроме функции обобщения требуется? </h4>

   <blockquote>
    <p> Никакого подсознания нет. Постоянное общение с миром может
                заключаться в обслуживании внутренних систем или в общении с учителем
                и т.п. Можно сказать так: постоянная работа мозга - это и есть
                подсознание. При этом существо, обладающее мозгом, может осознавать
                себя и некоторые свои мысли или не осознавать. То, что не осознанно
                назовём подсознанием или бессознательным. Фактически вся работа
                мозга не осознаётся. Осчознаётся только "работа тела" и "ощущения".
                Так что у бабочки сплошное подсознание, а у человека есть 1% сознания.
                Как это проверить? </p>
   </blockquote>

   <h4> Нужно ли нейронам спать?
    <br> Имеет ли смысл части сети отключиться от всех и заняться
            собственным обустройством? </h4>

   <blockquote>
    <p> Смотри ответ о подсознании. </p>
   </blockquote>

   <h4> Имеет ли смысл отключать входы от среды? </h4>

   <blockquote>
    <p> На самом деле во время сна отключается только сознание (осознание
                себя). При этом мозг общается только с беспристрастным объектным
                миром (например, с внутренними органами тела). Возможно, что осознаваемые
                мысли и умозаключения в силу своей необъективности могут нарушить
                логическую настройку мозга. И ему приходится спать, для исправления
                "сознательно сделанных" ошибок.
     <br> <i> Этот пассаж о сне послать в relcom.sci.philosophy. </i> </p>
   </blockquote>

   <h4> Можно ли иметь общую таблицу для перекодировки и коммутации? </h4>

   <blockquote>
    <p> Кажется, можно обойтись без коммутации. Единицей информации
                может быть, например, "лексема" - буква или слово или
                фраза. Нейроны не обязаны обрабатывать лексемы. Перекодирование
                битов в лексемы по таблице происходит только на входе и выходе
                системы в "словаре". Важно, что сам список лексем может
                формироваться путем накопления реакций среды. Так область интересов
                ученика может стать совершенно произвольной: беседа на заданную
                тему, идентификация, ориентация, перевод и т.д. Таблица лексем
                имеет ограниченный размер. Поэтому анализатор лексем должен добавлять
                в таблицу новые лексемы вместо устаревших или редко применяемых
                лексем. </p>
   </blockquote>

   <h4> Важно ли, чтобы нейроны работали параллельно или допустима
            последовательная обработка сигналов? </h4>

   <blockquote>
    <p> Важна не сама параллельность, а наличие времени исполнения
                команды нейроном. Так логический сигнал, проходящий через многие
                узлы сети, будет больше задерживаться, чем тот, который проходит
                по короткому пути. Поэтому полезно ввести такты перекодировки.
                Задержка логического сигнала приводит к тому, что при получении
                оценки запоминается последовательность предшествующих действий
                (перекодировок), а не просто текущее состояние таблиц. Один такт
                состоит в приеме сигнала во входной буфер и расчете сигнала в
                выходном буфере. Но, конечно, параллельность, в буквальном смысле
                слова, сильно ускоряет работу. </p>

    <p> Вернее, важна не задержка сигнала, а правильное
     <i> сохранение
                    последовательностей причин и следствий </i> в среде обрабатываемых
                данных. </p>
   </blockquote>

   <h4> Что нужно для развития предвидения, прогноза? </h4>

   <blockquote>
    <p> Важно на начальном этапе обучения, чтобы вместе с поступлением
                положительной оценки поступал и сигнал от среды на какие-то определенные
                входы системы. Тогда разовьется рефлекс и цель к достижению не
                только положительной оценки, но и к получению этого сигнала от
                среды (ассоциация). Нужно только запоминать диалог. </p>

    <p> Прогноз - это результат умозаключения (не обязательно - осознаваемого),
                при котором в памяти была найдена аналогичная ситуация, а если
                ситуация сложная, то отдельные её фрагменты могут иметь свои прогнозы,
                а из них могут следовать дальнейшие логические или "аналогичные"
                (индуктивные) прогнозы. </p>
   </blockquote>

   <h3 id="BM7">
    Задача 1. </h3>

   <p> Пусть мир представляет собой круг, в одной точке которого
            находится еда (положительная оценка). Обучаемая система может
            делать шаг влево или вправо вдоль окружности (выдавая 0 или 1
            на выход). Мир реагирует на это перемещением точки влево или вправо.
            При попадании в точку с едой мир выдает положительную оценку,
            и сигнал (еду) на вход. При этом обучающаяся система может содержать
            1 нейрон с 1 выходом и 2 входами (1 для еды и 1 для информации
            о своем перемещении). Координаты тела в пространстве это свойство
            тела или среды? </p>

   <p> Правильное поведение системы после обучения:
    <i> шаг от еды,
                назад к еде </i> и т.д. Причем все равно, куда шагать от еды:
            влево, вправо, то туда то сюда. </p>

   <table class="sel border">
    <tbody>
     <tr>
      <td> &nbsp; </td>
      <td> Вход </td>
      <td> Выход </td>
      <td> Вход </td>
      <td> Выход </td>
      <td> Вход </td>
      <td> Выход </td>
     </tr>
     <tr>
      <td> Текущий шаг: </td>
      <td> Еда </td>
      <td> X </td>
      <td> Нет </td>
      <td> Вправо </td>
      <td> Нет </td>
      <td> Влево </td>
     </tr>
     <tr>
      <td> Предыдущий шаг: </td>
      <td> X </td>
      <td> &nbsp; </td>
      <td> Влево </td>
      <td> &nbsp; </td>
      <td> Вправо </td>
      <td> &nbsp; </td>
     </tr>
    </tbody>
   </table>
   <p> В виде битовой таблицы: </p>

   <table class="sel border">
    <tbody>
     <tr>
      <td> 00 </td>
      <td> 1 </td>
     </tr>
     <tr>
      <td> 01 </td>
      <td> 0 </td>
     </tr>
     <tr>
      <td> 10 </td>
      <td> 0 или 1 </td>
     </tr>
     <tr>
      <td> 11 </td>
      <td> 0 или 1 </td>
     </tr>
    </tbody>
   </table>
   <p> Стимул должен действовать не менее 2, 3 шагов. (?) </p>

   <p> Похоже, что всегда требуется дублирование всей выходной информации.
            Таким образом, можно в качестве выходов использовать произвольные
            выходы нейронной сети, подключенные к каким-либо входам. Это нужно
            не только для того, чтобы знать свои шаги, но и для обеспечения
            возможности запоминать порядок шагов. </p>

   <h3 id="BM8">
    Задача 2. (Та же обучаемая система из 1 нейрона). </h3>

   <p> Пусть мир представляет собой круг, в одной точке которого
            находится еда, а в диаметрально противоположной точке - педаль.
            Еда исчезает при "съедании". При прохождении педали
            еда появляется вновь. Обучаемая система может делать шаг влево
            или вправо вдоль окружности (выдавая 0 или 1 на выход). Мир реагирует
            на это перемещением точки влево или вправо. При попадании в точку
            с едой мир выдает положительную оценку, и сигнал (еду) на вход.
            Педаль невидима. При этом обучающаяся система может содержать
            1 нейрон с 1 выходом и 2 входами (1 для еды и 1 для информации
            о своем перемещении). </p>

   <p> Правильное поведение системы после обучения:
    <i> бег по кругу. </i> </p>

   <table class="sel border">
    <tbody>
     <tr>
      <td> &nbsp; </td>
      <td> Вход </td>
      <td> Выход </td>
      <td> Вход </td>
      <td> Выход </td>
     </tr>
     <tr>
      <td> Текущий шаг: </td>
      <td> X </td>
      <td> Влево </td>
      <td> X </td>
      <td> Вправо </td>
     </tr>
     <tr>
      <td> Предыдущий шаг: </td>
      <td> Влево </td>
      <td> &nbsp; </td>
      <td> Вправо </td>
      <td> &nbsp; </td>
     </tr>
    </tbody>
   </table>
   <p> В виде битовой таблицы: </p>

   <table class="sel border">
    <tbody>
     <tr>
      <td> 00 </td>
      <td> 0 </td>
     </tr>
     <tr>
      <td> 01 </td>
      <td> 1 </td>
     </tr>
     <tr>
      <td> 10 </td>
      <td> 0 </td>
     </tr>
     <tr>
      <td> 11 </td>
      <td> 1 </td>
     </tr>
    </tbody>
   </table>
   <p> Времени действия стимула должно хватать почти на полный круг.
            То есть, найденное правильное поведение не должно полностью забываться
            за время долгого безуспешного движения в правильном направлении. </p>

   <h3 id="BM9">
    05 декабря 1996. Элементы памяти </h3>

   <p> Большим и умным нейронам, у которых много входов и выходов,
            я бы предпочел много маленьких и глупых. Они могут запомнить более
            длительные последовательности шагов (глубоко продумывать), чем
            люди всегда восхищаются. А большого ума от искусственного разума
            никто и не ждет. То есть и большой нейрон хорош, если он может
            запомнить процесс. </p>

   <p> Для усиления функции времени, возможно, надо сделать обязательным
            учет каждым нейроном своего предыдущего состояния, а учет предыдущих
            состояний других нейронов происходит сам собой. При этом можно
            уменьшить число входов. Пусть нейрон имеет 4 входа и 2 выхода
            для бит. На 2 входа подаем оба выхода. Остается 2 входа и 2 выхода
            (как и было) для внешнего применения. Таким образом, для введения
            обратной связи важно увеличить число входов, а не выходов. </p>

   <p> Таблица имеет вид: 0000 - XX (первые 2 бита - внешние входы,
            следующие - предыдущее состояние на выходах), 0001 - XX и т.д. </p>

   <p> Число строк таблицы: 16, разрядность выхода: 2. Размер таблицы:
            16 x 2 = 32 бита. Если бы нейрон имел 1 выход и 2 входа, то таблица
            имела бы размер 8 бит = 1 байт. </p>

   <p> Пример обратной связи. Пусть нужно иметь 4 входа и 3 выхода.
            Добавим 3 входа. Всё с выходов подадим на эти новые 3 входа. Получим
            нейрон с "сознанием". Добавим ещё 3 входа и 3 выхода
            и подадим 3 новых выходных сигнала на 3 новых входа. Получим нейрон
            с сознанием и подсознанием. Всего он имеет 10 входов и 6 выходов,
            из которых 4 входа и 3 выхода доступны, а остальные - скрыты. </p>

   <h3 id="BM10">
    07 декабря 1996. Польза памяти. </h3>

   <p> Каждый нейрон имеет внутреннее время реагирования и зависимость
            результата перекодировки от своего предыдущего состояния. Эту
            зависимость можно обобщить до нескольких предыдущих состояний. </p>

   <p> Тогда можно обучить единственный нейрон довольно продолжительной
            последовательности действий. Можно ввести реагирование с задержкой
            несколько тактов. Тогда нейрон приобретает свойства линии задержки
            или стека. Можно объединить все подобные свойства в одном нейроне.
            Но методически лучше создать нейрон, имеющий все необходимые функции
            в минимальной комплектации, так, чтобы более сложный нейрон можно
            было смоделировать путем правильного соединения нескольких простых
            нейронов. </p>

   <p class="center">
    <img alt="Два входа, два выхода" height="170" src="images/96-02.gif" title='"Минимальный
      нейрон"' width="313"> </p>

   <p> Цикл работы нейронной сети состоит из повторяющихся шагов:
            запоминаем то, что подано на входы всех нейронов и рассчитываем
            выходные сигналы. </p>

   <p> Если нейрон не хранит никаких данных, кроме тех, которые имеются
            на входах, то он уже может задерживать сигнал на 1 такт. Свое
            предыдущее состояние он может учитывать, если подсоединить выход
            o2 к входу i2. </p>

   <p class="center">
    <img alt="Обратная связь по одному каналу" height="186" src="images/96-03.gif" title="Обратная связь с задержкой на 1 такт позволяет помнить
      1 такт" width="317"> </p>

   <p> Нейрон на рис.1 способен обучиться задаче 2, нейрон на рис.2
            - задаче 1 и 2. </p>

   <p> Если нейроны малы и имеют примитивную таблицу перекодировки,
            то нет смысла её обобщать, потому что поиск одинаковых таблиц
            отнимет больше ресурсов, чем их дублирование. </p>

   <p> В общем, нейрон с задержкой состоит из чистой линии задержки
            на входе и таблицы перекодировки, принимающей сигнал от линии
            задержки во всю её длину. У такого нейрона таблица перекодировки
            может быть большой, и появляется смысл хранить такие таблицы отдельно
            и использовать их для поиска обобщений. </p>

   <p class="center">
    <img alt="Цепочка из трёх нейронов" height="403" src="images/96-04.gif" title="Пример
      включения нескольких нейронов" width="403"> </p>

   <p> Пусть нейрон имеет 3 входа Ni и 3 выхода No и помнит 3 такта
            Nt (текущий и два предыдущих такта). Тогда линия задержки подаёт
            на таблицу 9 бит. Таблица имеет объем S = 3 x 2
    <sup> 9 </sup> / 8 = 192 байта. </p>

   <p class="big">
    S = No 2
    <sup> Ni Nt </sup> </p>

   <p class="center">
    <img alt="Память в виде линии задержки" height="270" src="images/96-05.gif" title="Обобщение линии задержки для запоминания процесса" width="330"> </p>

   <p> Биологический нейрон, видимо, не может помнить больше 2 тактов. </p>

   <h3 id="BM11">
    Структура сети. </h3>

   <p> Нет проблем с выходами от сети к датчикам среды. Можно в качестве
            выходов использовать любые выходы нейронов. Однако в качестве
            входов сети можно использовать только свободные входы нейронов.
            Чтобы не портить сеть, построенную без разрывов, лучше иметь нейроны
            с избытком входов. В конце концов, все неиспользуемые входы можно
            подключить к любым выходам. Пусть число выходов на 1 меньше, чем
            входов. Тогда размер полной таблицы равен </p>

   <p class="big">
    S = (Ni-1) 2
    <sup> Ni Nt </sup> </p>

   <p> Пусть
    <i> минимальный нейрон </i> имеет 2 входа и 2 такта
            памяти. Таблица имеет объем S = 2
    <sup> 4 </sup> / 8 = 2 байта.
            Вначале, для упрощения, не будем отделять таблицы от нейронов.
            А в перспективе и таблицы и линии задержки должны быть самостоятельными
            объектами. </p>

   <h4> Какова топология сети, допускающей добавление нейронов? </h4>

   <blockquote>
    <p> Разорвем какую-нибудь связь выход-вход в сети и вставим в
                неё пару вход-выход нового нейрона. И так для всех пар вход-выход
                этого нейрона. Лишние входы подключим к любым точкам сети. </p>
   </blockquote>

   <h3 id="BM12">
    "Обучение за ручку", "Обучение на
                примерах". </h3>

   <p> Для того чтобы нейронная сеть (NN) могла так обучаться, нужно
            обеспечить возможность подмены выходного сигнала. </p>

   <p class="center">
    <img alt="С выхода нейрона сигналы попадают
      на входы других нейронов" height="226" src="images/96-06.gif" title="Обычное распределение данных
      без супервизора" width="259"> </p>

   <p class="center">
    <img alt="Один из выходов для контроля
      супервизором" height="346" src="images/96-07.gif" title="Контроль выхода отдельного нейрона для быстрого
      обучения" width="532"> </p>

   <h3 id="BM13">
    10.12.96. Что называют NN по литературе. </h3>

   <p> Общепринятое понятие нейронной сети подразумевает нечто очень
            похожее на живой мозг. Нейроны суммируют сигналы, поступающие
            от аксонов других нейронов через точки контакта, называемые синапсами.
            Синапсы способны помнить перекодировку, которая состоит лишь в
            ослаблении (усилении) сигнала с неким коэффициентом. Все коэффициенты
            всех синапсов - это и есть то, что помнит нейронная сеть. То есть,
            она "помнит" не данные, а свое состояние. Если это аналоговая
            сеть, то можно построить очень мощные обучающие алгоритмы, например,
            с использованием метода сопряженных градиентов. Если коэффициенты
            имеют дискретные (бинарные) значения, то для обучения можно использовать
            симплексный метод минимизации. Мне кажется, что такие классические
            нейронные сети несколько проще моей сети, но значительно хуже
            способны к обучению или самообучению. </p>

   <h3 id="BM14">
    Обобщение для слишком умных нейронов. </h3>

   <p> Пусть таблиц перекодировки не много и нейроны заранее пользуются
            общими таблицами. Одновременно с обучением или с обычной работой
            сети, применяем два постоянно идущих процесса "поиска обобщений"
            и "проверки обобщений". </p>

   <p> <b> Поиск обобщений </b> состоит в том, что две близкие, но
            разные таблицы заменяются одной. Например, это может быть пара
            наиболее близких таблиц из последней просмотренной сотни таблиц.
            Оба нейрона, использовавшие эти 2 таблицы начинают использовать
            только одну из них, а другая освобождается. </p>

   <p> <b> Проверка обобщений </b> состоит в том, что освободившаяся
            таблица применяется для разделения какой-то общей таблицы, применяемой
            в этот момент какой-то другой парой нейронов. Можно запоминать,
            для каких таблиц проводится проверка обобщений и при удачной проверке
            давать этим таблицам положительную оценку. Такой алгоритм позволяет
            содержать достаточно умные нейроны и включить поиск обобщений
            в подсознание. </p>

   <p> В литературе
    <i> обобщением называют способность к интерполяции </i> . Сеть научили реагировать на примерах. Затем ей подают на
            вход данные, которые не были использованы при обучении. Она выдает
            что-то близкое к тому, чему её учили. </p>

   <h3 id="BM15">
    Наиболее общий (аналоговый) нейрон </h3>

   <p> На вход нейрона поступают аналоговые данные u1(t), u2(t) ...
            На выходе появляются функции U1(t), U2(t) ..., которые зависят
            от текущих и предыдущих значений входных сигналов. Обобщение возникает
            из-за ограниченности множества выходных реакций нейрона и/или
            из-за квантования входных сигналов. Объединение любого количества
            таких нейронов в любую сеть логически эквивалентно одному нейрону.
    <i> Для правильного учета темпа поступления данных </i> , то есть
            производных по времени от u1, u2 и т.д
    <b> . , нужно, чтобы время
                внутри нейрона текло, не останавливаясь </b> , не зависимо от
            входных данных. Учет предыдущих значений входных (и выходных)
            функций
    <i> это не просто интеграл </i> , так как интеграл есть
            лишь суммирование с весом, а нейрон потенциально должен уметь
            делать более сложные (произвольные) преобразования. </p>

   <p> Некая таблица U(u) перекодировки входного сигнала и его прошлых
            значений в выходной сигнал это "ассоциативная память".
            Значения u и U могут все время слегка случайно портятся. </p>

   <p> Скорость забывания у каждого u разная и определяется полученными
            оценками. Память улучшается при хорошей оценке и ухудшается при
            плохой. Она также ухудшается сама собой со временем. (Это домыслы). </p>

   <p> Данные в ассоциативной памяти не обязательно портятся от времени.
            Просто, наименее надежные или устаревшие данные, со временем,
            будут замещены вновь поступившими данными. Это можно назвать забыванием. </p>

   <p> Линия задержки в нейроне это не следствие желания смоделировать
            задержку сигнала в нейронной сети. Это средство учета предыдущих
            входных состояний нейрона (или сети). </p>

   <h3 id="BM16">
    Реальный обучаемый нейрон </h3>

   <p> При ограниченных ресурсах данные становятся дискретными, входная
            линия задержки конечной. Поэтому приходится применять дополнительные
            средства, повышающие скорость обучения. Главное средство это введение
            "сознания". Если часть выходных данных направить не
            в среду, а на вход, то появляющаяся скрытая обработка информации
            позволяет запоминать последовательность действий даже без входной
            линии задержки. Если часть выходящих в среду данных направить
            также и на вход, то становится возможным "сознательное"
            выполнение действий в зависимости от предыдущих действий, а не
            только от реакции среды. </p>

   <p class="center">
    <img alt="Подсознание и сознание - это
      разные виды обратной связи в сети" height="261" src="images/96-08.gif" title="Общая схема нейронной
      сети с обратными связями" width="336"> </p>

   <p> <b> Подсознание </b> : информационный обмен внутри системы,
            скрытый от среды и от самого субъекта. </p>

   <p> <b> Сознание </b> : информационный обмен между элементами
            системы через внешние каналы связи. </p>

   <p> <b> Самосознание </b> (осознание себя): Сознание + физическое
            восприятие себя (своего тела или результатов своих действий) через
            внешний мир. </p>

   <p> Эти "объективистские" определения сильно отличаются
            от традиционных и не стоят внимания. </p>

   <p> Если такая самообучающаяся система имеет единственную матрицу
            перекодировки, то можно применять жесткое обучение. Для этого
            вписывают в строки матрицы нужные реакции при заданных входных
            сигналах. Самообучение и обучение на примере (за ручку) тоже работают.
            Обобщения возможны не только между нейронами, но и внутри одного
            нейрона. Обобщаются близкие строки матрицы. Это удобно назвать
            ассоциативной памятью. </p>

   <p> <a href="../post/email.html" rel="author" title="email и копирайт">
     Евгений Корниенко </a> </p>
  </main>

  <div id="menu">
  </div>

  <footer>
  </footer>

  <noscript>
   <div>
    
   </div> </noscript>
 </body>
</html>