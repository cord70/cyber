<!DOCTYPE html>
<html lang="en">
 <head>
  <title> Dangerously intelligent </title>
  <meta content="Artificial conscious beings will develop exponentially because they don't need to study what is already known to their predecessors." name="description">
  <meta content="clever bomb, cyber, cyber war, learning, personal weapon, selflearning, sensing, " name="keywords">
  <meta content="Eugene Kornienko" name="author">
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1" name="viewport">
  <link href="https://cord70.github.io/cyber/mind/danger-en.html" hreflang="en" rel="alternate">
  <link href="https://cord70.github.io/cyber/mind/danger.html" hreflang="ru" rel="alternate">
  <link href="https://cord70.github.io/cyber/mind/danger-en.html" rel="canonical">
  <link href="https://cord70.github.io/cyber/favicon.svg" rel="icon" sizes="any" type="image/svg+xml">
  <link href="../images/main.css" rel="stylesheet">
  <script defer="" src="navMind.js"> </script>
  <script defer="" src="../images/ansimeta.js"> </script>
 </head>
 <body>

  <header>
  </header>

  <main>
   <p class="headquote">
    Conscious machines will develop exponentially
            because they don't need to waste their time for studying what
            their predecessors already know. </p>

   <h2 id="dintelli">
    Dangerously intelligent </h2>

   <h4> <a title="author">
     Eugene Kornienko </a> </h4>

   <blockquote>
    <p> <i> In 1997 in comp.ai.philosophy I discussed the subject
                    with Louis Savain, Chris Hooley and William Modlin. </i> </p>
   </blockquote>

   <h4> In future I see conscious weapon. </h4>

   <p> What will happen if an algorithm of artificial mind is common
            known? It will be not a half-live computer virus, but a well thinking
            soulless machine. Such a machine cannot feel with or appreciate
            human's feelings because our "high" senses (humor, lonely...)
            originate from self-preserving that is a property of life, not
            of intelligence. </p>

   <p> Artificial intelligence is not an expensive and sophisticated
            A-bomb technology. It merely is an easily copied program. What
            if the algorithm doesn't need much of computing? I think that
            properly organized associative brain, which is as smart as mammal's
            one, could be placed in a desktop computer. </p>

   <p> Every tyrant and bandit wishes such accomplice. </p>

   <p> The understanding of a danger cannot stop it, especially then
            AI technology does world round spread. War and suicide are disastrous,
            too. But we do it. </p>

   <p> I think that
    <i> power of money </i> is the only hope to escape
            the new technology danger. State budget and personal wallet might
            win possible military application of AI because the AI is extremely
            needed in common life. </p>

   <p> <b> The problem of artificial mind will be solved soon. </b> And we cannot prepare ourselves for the new era in principle. </p>

   <p> At first we will teach robots to what is useful for us. Then
            AI entities will develop exponentially because they don't need
            to waste their time for studying what their predecessors have
            already known. The knowledge will accumulate not in books (and
            teachers) but in the robot's brains. </p>

   <p> It's impossible that a conscious robot, who is 10 times clever
            than I, were my servant. On the contrary, we will turn to servants
            of next robot generations, which will multiply their knowledge
            by 10 times per annum. </p>

   <h4> Awakening of machine consciousness. </h4>

   <p> It is accepted that consciousness arises as a way of
    <i> adaptation </i> . Thus, making adapting robots, we make conscious systems.
            Firstly they look merely like adaptive programs. So that even
            the most far-seeing of us don't appreciate the systems are conscious.
            A baby also doesn't look too conscious. </p>

   <p> Today the word
    <i> intelligent </i> is used as a commercial
            mark. We are ready to see elements of consciousness in an operating
            system. Are they in animals? Is a dog only intelligent (behaves
            rationally) or it is sentient and aware of itself? The machine-like
            intelligence comes to consciousness then an entity discovers that
            its condition depends on its action. Feel arises.
    <b> Conscious
                thing recognizes its own behavior. It distinguishes its own behavior
                from other events. It differentiates itself from other things. </b> </p>

   <p> So every more or less complex adaptive system, that we are
            inclined to call intelligent, is potentially conscious. From its
            creation an intelligent thing behaves intelligently; a conscious
            thing finds its own behavior - it adapts. And we subjectively
            evaluate, is this behavior really intelligent? I can imagine a
            system that fluently speaks but is firmly programmed. On the other
            hand such simple entity as Aplysia invents its own simple behavior
            without any programming. Its brain couldn't know the surrounding
            where the Aplysia will live. It has a tiny seed of genuine consciousness.
    <b> Consciousness stems from adaptation, not from complexity. </b> </p>

   <p> Living entities adapt to their life conditions not because
            they have conscious goal
    <i> to survive </i> . They care of food,
            of ceasing pain. Personal surviving, bearing and death are intangible
            abstractions. A cockroach runs away because it foresees "it
            will be worst", not because it is afraid of death. The natural
            selection, caring of cockroach's surviving, gave him capacity
            for foreseeing. </p>

   <p> Evolution developed brain that serves for surviving of species,
            not especially for thinking. Capacity for foreseeing eventually
            turned to thinking about oncoming events and actions. Such a gift
            of nature, for those who love thinking, probably helps us to survive,
            too. Understanding and valuing this capacity we intend to create
            machines that thinks and are aware of self. I believe the machine
            doesn't need so much of resources as a human brain does because
            their brain doesn't need to care of surviving. </p>

   <h4> We will spread the machines all over the world. </h4>

   <p> Designer unable to control its robot entire behavior. Moreover,
            not every designer wishes trace carefully his creature. Often
            the designer intentionally gives a freedom for, say, a computer
            virus. Generally, there are many things, we create, which are
            not fully controlled in principle. Our children, for instance,
            are. AI is the second example. </p>

   <p> Perhaps the first
    <i> tiny intelligence </i> will possess
            a
    <i> tiny free will </i> . But we pretend to make real mind that
            may compete with human's one. So I believe the "simple intelligence"
            is only the first step towards the purpose. Eventually the problem
            of making synthetic mind, that has its drives and free will, will
            be solved. </p>

   <p> If you allow the intelligent machine to make a decision, you
            cannot know what will the decision be. You also may not be sure
            that you will be satisfied with the decisions. Are you always
            satisfied with your own decisions? So the machine can realize
            its own will in accordance with its own judgement, even if you
            don't wish that. </p>

   <h4> Artificial selection of robots. </h4>

   <p> We might use artificial selection to grow
    <i> useful </i> generations of AI. Such a selection or terminating of non-proper
    <i> artificial </i> entities was successfully applied, say, in
            breeding of new dogs. But how do you imagine the terminating of
            an entity that is clever and is
    <i> more sentient </i> than you
            are, especially, if it does value itself and its consciousness? </p>

   <p> Well-developed robots can invent the "gating algorithms"
            to pass through our "artificial" selection. If a conscious
            entity values itself it tries to pass the selecting gate by all
            means and tricks. By such a way we will select extremely sophisticated
            and insincere robots. Free enough education is less dangerous,
            I think. </p>

   <p> I see the only way that gives us a hope of peaceful co-existence
            with robots. When the robots possess human power of intellect
            and when they interfere to our social life we must give advanced
            AI right of vote and also the right to be elected. Then the selection
            of moralities, which acts in democracy, will select AI entities
            for our (electorate) taste. Until the process is stable I hope
            we will not create too powerful robots. However this hope is logically
            unsupported. </p>

   <p> Finally nothing alive is needed for new generation of synthetic
            life. Thank God if we will become pets and toys. </p>

   <p> <a href="../post/email-en.html" rel="author" title="my email
      and copyright are here">
     Eugene Kornienko </a> </p>

   <p> 1997 </p>
  </main>

  <div id="menu">
  </div>

  <footer>
  </footer>

  <noscript>
   <div>
    
   </div> </noscript>
 </body>
</html>